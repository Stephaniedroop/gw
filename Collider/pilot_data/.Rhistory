# I think for c1,c4, c5, d1, d6, d7, we can just switch the answers
# But for the others, for TRIALTYPE, they have to be changed as follows:
# c2 goes to c3
# c3 goes to c2
# d2 goes to d4
# d3 goes to d5
# d4 goes to d2
# d5 goes to d3
# To do this, we'll take an intermediate column and then start replacing values
data1$cbtt <- data1$trialtype
data1$cbtt[data1$trialtype=='c2'] <- 'c3'
data1$cbtt[data1$trialtype=='c3'] <- 'c2'
data1$cbtt[data1$trialtype=='d2'] <- 'd4'
data1$cbtt[data1$trialtype=='d3'] <- 'd5'
data1$cbtt[data1$trialtype=='d4'] <- 'd2'
data1$cbtt[data1$trialtype=='d5'] <- 'd3'
# Now we can flip all the answers
# Store indices of which answers are already a and which are b
aans <- as.vector(1:4)
bans <- as.vector(5:8)
# Create new var where they are flipped
data1$intans <- data1$ans
data1 <- data1 %>% mutate(anscb = if_else(ans %in% aans, intans+4, intans-4))
data1 <- data1 %>% select(-c(trialtype,ans)) %>% rename(trialtype = cbtt, ans = anscb)
# Now rearrange the cols we need
data1 <- data1 %>% select(1:6,13,14,16)
data0 <- data0 %>% select(1:6,14,13,15)
data <- rbind(data0,data1) # 3456 of 9
# Map the answers they gave to the variables, in three increasing levels of granularity
# 1. Just the 4 variables, irrespective of the value they took
data <- data %>% mutate(ansVar = if_else(ans==1|ans==2, 'A',
if_else(ans==3|ans==4, 'Au',
if_else(ans==5|ans==6, 'B', 'Bu'))))
# 2. Six values, ie A and B are observed so don't need options, but unobserved Au and Bu can take either value
data <- data %>% mutate(ansVar2 = if_else(ans==1|ans==2, 'A',
if_else(ans==3, 'Au=1',
if_else(ans==4, 'Au=0',
if_else(ans==5|ans==6, 'B',
if_else(ans==7, 'Bu=1', 'Bu=0'))))))
# 3. Eight values: each var can take either value
data <- data %>% mutate(ansVar3 = if_else(ans==1, 'A=1',
if_else(ans==2, 'A=0',
if_else(ans==3, 'Au=1',
if_else(ans==4, 'Au=0',
if_else(ans==5, 'B=1',
if_else(ans==6, 'B=0',
if_else(ans==7, 'Bu=1', 'Bu=0'))))))))
# -------- Permissable actual cause analysis -----------
# Checks whether ppt's answers are permissable as per Tadeg's (via Halpern) actual causation condition
# NOTE: the var "possAns" is indexed 1:8 and was stored in worlds only for this, not for any use in javascript
# Get .possAns out of json
js <- worldsdf %>% select(ends_with("possAns"))
# Remove .possAns string from colnames, transpose so easier to search and add 1 to every cell because js indexes from 0
colnames(js) <- sub(".possAns", "", colnames(js))
js <- t(js)
# Empty vec to put the answers in, same order and size as
isPerm <- rep(NA, 3408) # Replace later - 3456 - I removed the cb=1 for a test
# (Long winded index match - would be good to know a better way)
for (k in 1:nrow(data))
{
row <- data[k,]
ttype <- row$trialtype
ans <- row$ans
jsvec <- js[ttype,1:8]
isposs <- ans %in% jsvec
isPerm[k] <- isposs
}
# Add to df1 (I checked it is right)
data <- cbind(data, isPerm)
# Now group by ppt to see if they mostly pick permissable answers. groupby subjectID first to see who is at it
tf <- data %>% group_by(isPerm) %>% summarise(n=n()) # They do
# -------- Coherent cause analysis -----------
# Checks whether ppt's answers are COHERENT in context of that situation
# A less stringent version of the previous analysis
# NOTE: the var "cohAns" is indexed 1:8 and was stored in worlds only for this, not for any use in javascript
# Get .cohAns out of json
jc <- worldsdf %>% select(ends_with("cohAns"))
# Remove .cohAns string from colnames, transpose so easier to search
colnames(jc) <- sub(".cohAns", "", colnames(jc))
jc <- t(jc)
# Empty vec to put the answers in, same order and size as
isCoh <- rep(NA, 3408) # Replace later - 3456 - I removed the cb=1 for a test
# (Long winded index match - would be good to know a better way)
for (k in 1:nrow(data))
{
row <- data[k,]
ttype <- row$trialtype
ans <- row$ans
jsvec <- jc[ttype,1:8]
iscoh <- ans %in% jsvec
isCoh[k] <- iscoh
}
# Add to df1 (I checked it is right)
data <- cbind(data, isCoh)
# Now group by ppt to see if they mostly pick permissable answers. Groupby subject id to see who is at it
tc <- data %>% group_by(isCoh) %>% summarise(n=n()) # They do
# ------------ Assign some new variables: pgroup then latent variables
# We now give a variable for probgroup, and then split the data into wee dfs for each one, a controversial decision that may backfire and get changed later
data <- data %>% mutate(pgroup = if_else(prob0=='10%' & prob1=='50%' | prob2=='10%' & prob3=='50%', '1',
if_else(prob0=='50%' & prob1=='80%' | prob2=='50%' & prob3=='80%', '2', '3')))
# Need an original probgroup to preserve the cb and see how we can compare them, to make sure there wasn't much bias
data$pgorig <- data$pgroup
data$pgorig[data$pgroup==1 & data$cb==1] <- 4
data$pgorig[data$pgroup==2 & data$cb==1] <- 5
data$pgorig[data$pgroup==3 & data$cb==1] <- 6
# And still to do these correlations, not sure how exactly yet...
# Later we might still split out these probgroups
# How often did they select latent variables?
data <- data %>% mutate(isLat = ifelse(ansVar=='Au'|ansVar=='Bu', TRUE, FALSE))
# But there is another more nuanced quality: realLatent...
# Sometimes the values of the unobserved variables can be inferred logically. These are NOT 'realLatent'.
# realLatent is when we genuinely don't know what values the unobserved variables take. (when poss >1 in the function `get_cond_probs`)
# It affects the following situations (easier to point out when it is NOT realLatent, and take the inverse)
# All unobserved are realLatent, except:
# c5: Au and Bu
# d2: Bu
# d3: Bu
# d4: Au
# d5: Au
# d6: Au and Bu
# Now encode those rules by putting FALSE. (Everything else is already correctly determined)
data$realLat <- data$isLat
data$realLat[data$trialtype=='c5'|data$trialtype=='d6'] <- FALSE
data$realLat[data$trialtype=='d2' & data$ansVar=='Bu'] <- FALSE
data$realLat[data$trialtype=='d3' & data$ansVar=='Bu'] <- FALSE
data$realLat[data$trialtype=='d4' & data$ansVar=='Au'] <- FALSE
data$realLat[data$trialtype=='d5' & data$ansVar=='Au'] <- FALSE
# We also want a variable denoting 'connected with var A' (including A and Au) and likewise for B
data <- data %>% mutate(connectedWith = ifelse(ansVar=='A'|ansVar=='Au', 'A', 'B'))
data <- data %>% rename(node3 = ansVar3)
# Do we still wanna group by pgroup?? That's an ongoing question
# Better save the data just in case
write.csv(data, '../Data/pptdata.csv') # and a big .csv with each trial as a row, no summary, for checking and reference
save(data, file="../Data/Data.Rdata")
View(tc)
94/3314
3314/3408
rm(list=ls())
load('../Data/Data.Rdata', verbose = T) # This is one big df, 'data'
mp <- read.csv('../model_data/tidied_preds2.csv') #
dataPropsLat <- data %>% # 72 of 4
group_by(pgroup) %>%
complete(trialtype, realLat) %>%
group_by(pgroup, trialtype, realLat) %>%
summarise(n=n()) %>%
mutate(prop = n/sum(n))
dataPropsLatnott <- data %>% # 6 of 4
group_by(pgroup) %>%
complete(trialtype, realLat) %>%
group_by(pgroup, realLat) %>%
summarise(n=n()) %>%
mutate(prop = n/sum(n))
dataPropsVar <- data %>%
group_by(pgroup, trialtype, connectedWith) %>%
summarise(n=n()) %>%
mutate(prop = n/sum(n)) # 72 of 5
dataPropsVar <- data %>%
group_by(pgroup, trialtype, connectedWith) %>%
summarise(n=n()) %>%
mutate(prop = n/sum(n)) # 72 of 5
### Divvying up the model predictions
Now we slice up the model predictions in the same way.
modelPropsLat <- mp %>% # 72 of 5
na.omit() %>%
group_by(pgroup) %>%
complete(trialtype, realLat) %>%
group_by(pgroup, trialtype, realLat) %>%
summarise(predicted = sum(wa)) %>%
replace(is.na(.), 0) %>%
mutate(normpred = predicted/sum(predicted))
modelPropsLatnott <- mp %>% # 6 of 4
na.omit() %>%
group_by(pgroup, realLat) %>%
summarise(predicted = sum(wa)) %>%
replace(is.na(.), 0) %>%
mutate(normpred = predicted/sum(predicted))
modelPropsVar <- mp %>% # 72 of 5
group_by(pgroup, trialtype, connectedWith) %>%
summarise(predicted = sum(wa)) %>%
mutate(normpred = predicted/sum(predicted))# 72 of 5
# Set pgroup as factor
dataPropsLat$pgroup <- as.factor(dataPropsLat$pgroup)
modelPropsLat$pgroup <- as.factor(modelPropsLat$pgroup)
dataPropsVar$pgroup <- as.factor(dataPropsVar$pgroup)
modelPropsVar$pgroup <- as.factor(modelPropsVar$pgroup)
dataPropsLatnott$pgroup <- as.factor(dataPropsLatnott$pgroup)
modelPropsLatnott$pgroup <- as.factor(modelPropsLatnott$pgroup)
# Set trialtype as factor
# We want to put conj and disc trialtypes on the same plot. But the names 'c1' etc are not informative
# So we need a vector of the spec for the labels:
fulltrialspec <- c('Disj: A=1, B=1, | E=1',
'Disj: A=1, B=1, | E=0',
'Disj: A=1, B=0, | E=1',
'Disj: A=1, B=0, | E=0',
'Disj: A=0, B=1, | E=1',
'Disj: A=0, B=1, | E=0',
'Disj: A=0, B=0, | E=0',
'Conj: A=1, B=1, | E=1',
'Conj: A=1, B=1, | E=0',
'Conj: A=1, B=0, | E=0',
'Conj: A=0, B=1, | E=0',
'Conj: A=0, B=0, | E=0')
# They should be:
# c1: 000
# c2: 010
# c3: 100
# c4: 110
# c5: 111
# d1: 000
# d2: 010
# d3: 011
# d4: 100
# d5: 101
# d6: 110
# d7: 111
trialvalsvec <- as.vector(unique(data$trialtype)) %>% sort(decreasing = TRUE)
# Set trialtype as factor
dataPropsLat$trialtype <- factor(dataPropsLat$trialtype, levels = trialvalsvec, labels = fulltrialspec)
modelPropsLat$trialtype <- factor(modelPropsLat$trialtype, levels = trialvalsvec, labels = fulltrialspec)
dataPropsVar$trialtype <- factor(dataPropsVar$trialtype, levels = trialvalsvec, labels = fulltrialspec)
modelPropsVar$trialtype <- factor(modelPropsVar$trialtype, levels = trialvalsvec, labels = fulltrialspec)
combPropsLat <- merge(x = modelPropsLat, y = dataPropsLat, all.x = T) %>%
select(-predicted, -n) %>%
rename(cesm=normpred, ppts=prop) %>%
pivot_longer(cols = cesm:ppts, values_to = 'percent')
combPropsVar <- merge(x = modelPropsVar, y = dataPropsVar, all.x = T) %>%
select(-predicted, -n) %>%
rename(cesm=normpred, ppts=prop) %>%
pivot_longer(cols = cesm:ppts, values_to = 'percent') %>%
na.omit()
combLatnott <- merge(x = modelPropsLatnott, y = dataPropsLatnott, all.x = T) %>%
select(-predicted, -n) %>%
rename(cesm=normpred, ppts=prop) %>%
pivot_longer(cols = cesm:ppts, values_to = 'percent') %>%
na.omit()
View(combLatnott)
View(dataPropsLatnott)
View(modelPropsLatnott)
View(combLatnott)
combLatnott %>% group_by(pgroup)
combLatnott %>% group_by(name, realLat)
combLatnott %>% group_by(name, realLat) %>% summarise(x = mean(percent))
chisq.test(x=c(0.802,0.198), y=c(0.763, 0.237))
View(modelPropsLatnott)
View(dataPropsVar)
View(dataPropsLat)
View(dataPropsLatnott)
dataPropsLatnott %>% group_by(realLat) %>% summarise(n=n())
dataPropsLatnott %>% group_by(realLat)
dataPropsLatnott %>% group_by(realLat) %>% summarise(x = mean(n))
dataPropsLatnott %>% group_by(realLat) %>% summarise(x = sum(n))
808/2607
808/(808+2607)
808+2607
3415*0.198
3415*0.802
2739+676
chisq.test(x=c(2607,808), y=c(2739,676))
chisq.test(x=c(2607,808), y=c(2739,676), p=c(0.5,0.5))
M <- as.table(rbind(c(2607,808),c(2739,676)))
chisq.test(M)
rm(list=ls())
# ---------- Get main data -----------
# Setwd for main data
setwd("../Data/batch") # as in, setwd("/Users/stephaniedroop/Documents/GitHub/gw/Collider/Data/batch")
# read in csvs
csvList <- lapply(list.files("./"), read.csv, stringsAsFactors = F) # this gives list of 10 when you're in the wd
# csvList <- lapply(list.files("./pilot_data"), read.csv, stringsAsFactors = F)
# bind them
dataset <- do.call(rbind, csvList) # 6650 obs of 20 vars
# Data rows were generated by different trials, but we can get everything we need in one row
# But first we need to replace spaces with NA
dataset <- dataset %>% mutate(across(c('answer'), ~na_if(.,"")))
# Then can fill upwards to get the text answer in the same place as the trial info
dataset <- dataset %>% fill(answer, .direction = 'up')
# ---------- Get jsons of static worlds info used in experiment ------
# Get the jsons
worlds <- fromJSON(file = '../../Experiment/worlds.json')
worldsdf <- as.data.frame(worlds) # 8 obs of 132 vars
conds <- fromJSON(file = '../../Experiment/conds.json')
condsdf <- as.data.frame(conds) # 2 obs of 21 vars
# ------------ Get pilot data -------------
# Setwd
setwd("../../pilot_data") # as in, setwd("/Users/stephaniedroop/Documents/GitHub/gw/Collider/pilot_data")
# read in csvs
csvList <- lapply(list.files("./"), read.csv, stringsAsFactors = F) # this gives list of 10 when you're in the wd
# csvList <- lapply(list.files("./pilot_data"), read.csv, stringsAsFactors = F)
# bind them
dataset2 <- do.call(rbind, csvList) # 250 of 20
# Get the feedback rows and comment out - THIS WAS PILOT ONLY
# feedback <- dataset[dataset$rowtype=='feedback',]
# Data rows were generated by different trials, but we can get everything we need in one row
# But first we need to replace spaces with NA
dataset2 <- dataset2 %>% mutate(across(c('answer'), ~na_if(.,"")))
# Then can fill upwards to get the text answer in the same place as the trial info
dataset2 <- dataset2 %>% fill(answer, .direction = 'up')
# --------- Get the first five pilot data -------------
pilot5 <- read.csv('../processed_data/pilot1.csv') %>% select(-(c(1,14,15)))
# Put them together
dataset <- rbind(dataset,dataset2)
# ---------- Now analysing all data together ---------
# 6950 obs of 15
# Remove empty cols and rows
dataset <- dataset %>% filter(cb!='NA') # Obs should be 12* no. of ppts, as each did 12 trials. 3509 of 13
# Here 3329 of 13 vars, so some did not complete. Find who is complete
s12 <- dataset %>% group_by(prolific_id) %>% summarise(n=n()) # 294
keep <- filter(s12,n==12) # 279
dataset <- dataset %>% filter(prolific_id %in% keep$prolific_id) # 3348
# NOW can remove the cols with long strings, and rbind with the pilot2 data (which we checked was complete at the time)
dataset <- dataset %>% select(-c(2:4,6,7))
dataset <- dataset %>% select(-c(13:14))
dataset <- rbind(dataset, pilot5) # 3408
# Put a column with structure - for some reason it doesn't have
data <- dataset %>% mutate(structure = if_else(grepl("^c", trialtype), 'conjunctive', 'disjunctive'))
# --------------- Processing the answers participants gave -----------------
# Now reattach the number of their answer, as atm it has only recorded the text on their radio button
# First here are the arrays of possible buttons from js exp.
jobanswers <- c('The candidate had skill A',
'The candidate did not have skill A',
'The candidate demonstrated skill A',
'The candidate did not demonstrate skill A',
'The candidate had skill B',
'The candidate did not have skill B',
'The candidate demonstrated skill B',
'The candidate did not demonstrate skill B')
cookanswers <- c('The chef completed the main dish',
'The chef did not complete the main dish',
'The main dish impressed the panel',
'The main dish did not impress the panel',
'The chef completed the dessert',
'The chef did not complete the dessert',
'The dessert impressed the panel',
'The dessert did not impress the panel')
groupanswers <- c('The lecturer attended',
'The lecturer did not attend',
'The lecturer talked about the paper',
'The lecturer did not talk about the paper',
'The postdoc attended',
'The postdoc did not attend',
'The postdoc talked about the paper',
'The postdoc did not talk about the paper')
# Now make a new column with the position in array of their answer
data <- data %>% mutate(ans = if_else(scenario=='job', match(data$answer, jobanswers),
if_else(scenario=='cook', match(data$answer, cookanswers),
match(data$answer, groupanswers))))
# There is one(!) cell in the data that stubbornly keep putting NA, even though I can see a legal answer in the original data
# No idea why. I am replacing manually
data[2861,15] <- 4
# ------------ The long road to reversing the counterbalancing -------------------
data0 <- data %>% filter(cb==0)
data1 <- data %>% filter(cb==1)
# HOLD EVERYTHING WHILE I GO TO ANOTHER SCRIPT AND SOLVE THIS
#write.csv(data1, '../data1.csv')
# also need to mix around some actual conditions
# I think for c1,c4, c5, d1, d6, d7, we can just switch the answers
# But for the others, for TRIALTYPE, they have to be changed as follows:
# c2 goes to c3
# c3 goes to c2
# d2 goes to d4
# d3 goes to d5
# d4 goes to d2
# d5 goes to d3
# To do this, we'll take an intermediate column and then start replacing values
data1$cbtt <- data1$trialtype
data1$cbtt[data1$trialtype=='c2'] <- 'c3'
data1$cbtt[data1$trialtype=='c3'] <- 'c2'
data1$cbtt[data1$trialtype=='d2'] <- 'd4'
data1$cbtt[data1$trialtype=='d3'] <- 'd5'
data1$cbtt[data1$trialtype=='d4'] <- 'd2'
data1$cbtt[data1$trialtype=='d5'] <- 'd3'
# Now we can flip all the answers
# Store indices of which answers are already a and which are b
aans <- as.vector(1:4)
bans <- as.vector(5:8)
# Create new var where they are flipped
data1$intans <- data1$ans
data1 <- data1 %>% mutate(anscb = if_else(ans %in% aans, intans+4, intans-4))
data1 <- data1 %>% select(-c(trialtype,ans)) %>% rename(trialtype = cbtt, ans = anscb)
# Now rearrange the cols we need
data1 <- data1 %>% select(1:6,13,14,16)
data0 <- data0 %>% select(1:6,14,13,15)
data <- rbind(data0,data1) # 3456 of 9
# Map the answers they gave to the variables, in three increasing levels of granularity
# 1. Just the 4 variables, irrespective of the value they took
data <- data %>% mutate(ansVar = if_else(ans==1|ans==2, 'A',
if_else(ans==3|ans==4, 'Au',
if_else(ans==5|ans==6, 'B', 'Bu'))))
# 2. Six values, ie A and B are observed so don't need options, but unobserved Au and Bu can take either value
data <- data %>% mutate(ansVar2 = if_else(ans==1|ans==2, 'A',
if_else(ans==3, 'Au=1',
if_else(ans==4, 'Au=0',
if_else(ans==5|ans==6, 'B',
if_else(ans==7, 'Bu=1', 'Bu=0'))))))
# 3. Eight values: each var can take either value
data <- data %>% mutate(ansVar3 = if_else(ans==1, 'A=1',
if_else(ans==2, 'A=0',
if_else(ans==3, 'Au=1',
if_else(ans==4, 'Au=0',
if_else(ans==5, 'B=1',
if_else(ans==6, 'B=0',
if_else(ans==7, 'Bu=1', 'Bu=0'))))))))
# -------- Permissable actual cause analysis -----------
# Checks whether ppt's answers are permissable as per Tadeg's (via Halpern) actual causation condition
# NOTE: the var "possAns" is indexed 1:8 and was stored in worlds only for this, not for any use in javascript
# Get .possAns out of json
js <- worldsdf %>% select(ends_with("possAns"))
# Remove .possAns string from colnames, transpose so easier to search and add 1 to every cell because js indexes from 0
colnames(js) <- sub(".possAns", "", colnames(js))
js <- t(js)
# Empty vec to put the answers in, same order and size as
isPerm <- rep(NA, 3408) # Replace later - 3456 - I removed the cb=1 for a test
# (Long winded index match - would be good to know a better way)
for (k in 1:nrow(data))
{
row <- data[k,]
ttype <- row$trialtype
ans <- row$ans
jsvec <- js[ttype,1:8]
isposs <- ans %in% jsvec
isPerm[k] <- isposs
}
# Add to df1 (I checked it is right)
data <- cbind(data, isPerm)
# Now group by ppt to see if they mostly pick permissable answers. groupby subjectID first to see who is at it
tf <- data %>% group_by(isPerm) %>% summarise(n=n()) # They do
# -------- Coherent cause analysis -----------
# Checks whether ppt's answers are COHERENT in context of that situation
# A less stringent version of the previous analysis
# NOTE: the var "cohAns" is indexed 1:8 and was stored in worlds only for this, not for any use in javascript
# Get .cohAns out of json
jc <- worldsdf %>% select(ends_with("cohAns"))
# Remove .cohAns string from colnames, transpose so easier to search
colnames(jc) <- sub(".cohAns", "", colnames(jc))
jc <- t(jc)
# Empty vec to put the answers in, same order and size as
isCoh <- rep(NA, 3408) # Replace later - 3456 - I removed the cb=1 for a test
# (Long winded index match - would be good to know a better way)
for (k in 1:nrow(data))
{
row <- data[k,]
ttype <- row$trialtype
ans <- row$ans
jsvec <- jc[ttype,1:8]
iscoh <- ans %in% jsvec
isCoh[k] <- iscoh
}
# Add to df1 (I checked it is right)
data <- cbind(data, isCoh)
# Now group by ppt to see if they mostly pick permissable answers. Groupby subject id to see who is at it
tc <- data %>% group_by(isCoh) %>% summarise(n=n()) # They do
# ------------ Assign some new variables: pgroup then latent variables
# We now give a variable for probgroup, and then split the data into wee dfs for each one, a controversial decision that may backfire and get changed later
data <- data %>% mutate(pgroup = if_else(prob0=='10%' & prob1=='50%' | prob2=='10%' & prob3=='50%', '1',
if_else(prob0=='50%' & prob1=='80%' | prob2=='50%' & prob3=='80%', '2', '3')))
# Need an original probgroup to preserve the cb and see how we can compare them, to make sure there wasn't much bias
data$pgorig <- data$pgroup
data$pgorig[data$pgroup==1 & data$cb==1] <- 4
data$pgorig[data$pgroup==2 & data$cb==1] <- 5
data$pgorig[data$pgroup==3 & data$cb==1] <- 6
# And still to do these correlations, not sure how exactly yet...
# Later we might still split out these probgroups
# How often did they select latent variables?
data <- data %>% mutate(isLat = ifelse(ansVar=='Au'|ansVar=='Bu', TRUE, FALSE))
# But there is another more nuanced quality: realLatent...
# Sometimes the values of the unobserved variables can be inferred logically. These are NOT 'realLatent'.
# realLatent is when we genuinely don't know what values the unobserved variables take. (when poss >1 in the function `get_cond_probs`)
# It affects the following situations (easier to point out when it is NOT realLatent, and take the inverse)
# All unobserved are realLatent, except:
# c5: Au and Bu
# d2: Bu
# d3: Bu
# d4: Au
# d5: Au
# d6: Au and Bu
# Now encode those rules by putting FALSE. (Everything else is already correctly determined)
data$realLat <- data$isLat
data$realLat[data$trialtype=='c5'|data$trialtype=='d6'] <- FALSE
data$realLat[data$trialtype=='d2' & data$ansVar=='Bu'] <- FALSE
data$realLat[data$trialtype=='d3' & data$ansVar=='Bu'] <- FALSE
data$realLat[data$trialtype=='d4' & data$ansVar=='Au'] <- FALSE
data$realLat[data$trialtype=='d5' & data$ansVar=='Au'] <- FALSE
# We also want a variable denoting 'connected with var A' (including A and Au) and likewise for B
data <- data %>% mutate(connectedWith = ifelse(ansVar=='A'|ansVar=='Au', 'A', 'B'))
data <- data %>% rename(node3 = ansVar3)
# Do we still wanna group by pgroup?? That's an ongoing question
# Better save the data just in case
write.csv(data, '../Data/pptdata.csv') # and a big .csv with each trial as a row, no summary, for checking and reference
save(data, file="../Data/Data.Rdata")
View(tc)
94/3408
3314/3408
View(tf)
3007/3408
getwd()
###############################################################
###### Collider - save parameters as probability vectors  #####
###############################################################
rm(list=ls())
# All the params we want, put into a list of 4x2 dfs
params1 <- data.frame("0"=c(0.9,0.5,0.2,0.5), "1"=c(0.1,0.5,0.8,0.5))
params2 <- data.frame("0"=c(0.5,0.9,0.5,0.2), "1"=c(0.5,0.1,0.5,0.8))
params3 <- data.frame("0"=c(0.9,0.3,0.2,0.5), "1"=c(0.1,0.7,0.8,0.5))
params4 <- data.frame("0"=c(0.5,0.5,0.5,0.5), "1"=c(0.5,0.5,0.5,0.5))
#params5 <- data.frame("0"=c(0.5,0.2,0.5,0.9), "1"=c(0.5,0.8,0.5,0.1))
#params6 <- data.frame("0"=c(0.2,0.5,0.9,0.3), "1"=c(0.8,0.5,0.1,0.7))
row.names(params1) <- row.names(params2) <- row.names(params3) <- row.names(params4) <-c ("pA",  "peA", "pB", "peB")
# <- row.names(params4) <- row.names(params5) <- row.names(params6)
names(params1) <- names(params2) <- names(params3) <- names(params4) <- c('0','1')
#<- names(params4) <- names(params5) <- names(params6)
poss_params <- list(params1, params2, params3, params4)
# , params4, params5, params6
save(file = '../model_data/params.rdata', poss_params)
