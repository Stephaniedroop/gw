---
title: "Combine participants and model predictions for stability parameter `r params$s`"
output: html_document
date: "2024-10-10"
params: 
  stab: 0.7
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Script takes the processed data from the collider ppt expt (`DATA.RDATA`)
# (which was cleaned and sliced in `mainbatch_preprocessing.R`) 
# and combines it with the preprocessed model predictions from `modpred_preprocessing.R` (`tidied_preds.csv`)
```

This code combines participant and model predictions at stability parameter `r params$stab`.


## Issues in how to lesion the model 

Tadeg's point: the step where the model averages 2-4 points (first chart on this page) to get the single point is too hard for ppl to do. So instead, they might do something simpler. Several ways to lesion the model to represent the simpler calculation people nay be doing are detailed in [notes]. 

Question is, for that do we still do the conditioning including unobserved vars in the function `get_cond_probs` in the 

## How to read these charts

The blue dotted line in the plots is a baseline of 12.5%, that is, the chance level of a participant choosing any variable (they were permitted to choose any).

The red dashed line is a much more conservative baseline of equal choice between only those answers that were coherent with actual causation, i.e., if the outcome was 0 in a disjunctive setting, when A was 1 and B was 0, then the only two coherent explanations for outcome 0 are Au=0 and B=0, as it is meaningless for Bu to have any value when B=0, and we know Au=0 because otherwise the effect would have occurred. There are always two coherent explanations, except for when both A and B occurred and the outcome occurred, when there are four (shown by red dashed line at 0.25 in those conditions).

Incoherent answers were permitted and were occasionally chosen by participants, but these bars are shown very faintly.

```{r, include=FALSE}
load('../Data/Data.Rdata', verbose = T) # This is one big df, 'data', 3408 obs of 18 ie. 284 ppts
mod <- read.csv('../model_data/tidied_preds2.csv') # 82656 of 31
mod$s <- as.character(mod$s)

mp <- mod[mod$s %in% params$stab, ]

mp$pgroup <- as.factor(mp$pgroup)
mp$node3 <- as.factor(mp$node3)
mp$trialtype <- as.factor(mp$trialtype)

modelNorm <- mp %>% # 288 of 5
  group_by(pgroup, trialtype, node3, .drop = FALSE) %>% 
  summarise(predicted = sum(wa)) %>% # TO DO - what happens if it is mean??
  mutate(normpred = predicted/sum(predicted))

# Just a check to make sure the normalisation still means the same even over 10x - thin it does, so what does this mean for the next calculation, for lesioned model where they don't do the bayesinf?

# (Need to redo the vis where all dots are shown....)
 
modelNorm4 <- mp %>% # 288 of 5
  group_by(pgroup, trialtype, node3, uAuB, .drop = FALSE) %>% 
  summarise(predicted = mean(wa)) %>% # TO DO - what happens if it is mean??
  mutate(normpred = predicted/sum(predicted))

# predicted is the same as wa2 from 5. When this then gets summed, it gives the unnormalised model prediction (ie for pg1, d7, A=1 is 0.34. This then normalises later)

modelNorm5 <- mp %>% # 288 of 5
  group_by(pgroup, trialtype, cond, node3, uAuB, .drop = FALSE) %>% 
  summarise(forplot = mean(cp)) %>% 
  mutate(wa2 = forplot*cond) #%>% # TO DO - what happens if it is mean??
  #mutate(normpred = predicted/sum(predicted))

# (There is potentially a problem with the normpred calc, as 1) it is summed over a) the 10 runs and b) the different unobs settings, and 2) it is dividing by the sum of the cesm for all the variables. 
# as in, I have not actuallty averaged anywhere.
# Should check and re-do to make sure

# An odd little way to bring in realLat status, must be a better way
modelPlaceholder <- mp %>% 
  na.omit() %>% 
  group_by(pgroup, trialtype, node3, realLat, .drop = FALSE) %>% 
  tally

# For realLat, everything TRUE has been defined as such. 
# Everything else needs to be FALSE (currently some are na because we used .drop=F to get all the combinations).
modelPlaceholder <- modelPlaceholder %>% replace(is.na(.), FALSE) %>% select(-n)

modelNorm <- merge(modelNorm, modelPlaceholder)

#modelNorms <- merge(modelNorms, modelPlaceholder, all.x = TRUE) # There are some NaNs and NA, can decide whether to replace with 0 later

# ------------- 2. Summarise participant data in same format ---------------------
# Section to get all combinations of variables, left join the participant answers of each, 
# and tag those with whether their answers are coherent or not (isPerm)


# First set factors so we can use tally
data$pgroup <- as.factor(data$pgroup)
data$node3 <- as.factor(data$node3)
data$trialtype <- as.factor(data$trialtype)
data$isPerm <- as.factor(data$isPerm)

# Some confusion over whether we want realLat or isPerm - and how to feed those things to the chart later
# We want both. realLat applies to both model and data, so is tagged here to model.
# isPerm is a data value so is tagged here to data. The combnorm takes them both to variable settings

# Bring in the isPerm status of all the node answers actually given
dataPlaceholder <- data %>% # 214
  na.omit() %>% 
  group_by(pgroup, trialtype, node3, isPerm) %>% # prob no need for .drop because the isPerm val is the same for both values of the var
  tally

dataNorm <- data %>% # 289
  group_by(pgroup, trialtype, node3, .drop=FALSE) %>% # Here we do need the .drop to get all the combinations
  tally %>% 
  mutate(prop=n/sum(n))

# Merge and keep all the 288 combinations, adding the isPerm vals for the ones that got an answer
dataNorm <- merge(x=dataNorm, y=dataPlaceholder, all.x = T) %>% replace(is.na(.), FALSE) %>% select(1,2,3,6,4,5)

# ----------- 3. The actual merge! ------------ 
# 576 of 7 -- CLOSEST THING TO SINGLE PREDICTION PER NODE/EXPLANATION 
combNorm <- merge(x=dataNorm, y=modelNorm) %>% 
  select(-predicted, -n) %>% 
  rename(cesm=normpred, ppts=prop) %>% 
  pivot_longer(cols = cesm:ppts, values_to = 'percent')

# But we also need a way to have all the model s_vals. What way round, who left? check it works up to here so far
# EITHER: a function to split out the mp for each s_val, then combine with data and sumamrise and plot
# OR combine everything at once, then split out to plot. Not sure yet

# One for the scatter plot
combNorm2 <- merge(x=dataNorm, y=modelNorm) %>% 
  select(-predicted, -n) %>% 
  rename(cesm=normpred, ppts=prop) %>% 
  filter(isPerm==TRUE)

# For by-facet correlations
combNorm3 <- merge(x=dataNorm, y=modelNorm) %>% 
  select(-predicted, -n) %>% 
  rename(cesm=normpred, ppts=prop) 

# save this as csv if you want it elsewhere
#write.csv(combNorm, 'combNorm.csv')
```


```{r, echo=FALSE}
# ------------ 4. Plot -----------------
# We want to put conj and disc trialtypes on the same plot. 
# But the trialtype names 'c1' etc are not informative
# So we need a vector of the spec for the labels:

fulltrialspec <- c('Disj: A=1, B=1, | E=1',
                   'Disj: A=1, B=1, | E=0',
                   'Disj: A=1, B=0, | E=1',
                   'Disj: A=1, B=0, | E=0',
                   'Disj: A=0, B=1, | E=1',
                   'Disj: A=0, B=1, | E=0',
                   'Disj: A=0, B=0, | E=0',
                   'Conj: A=1, B=1, | E=1',
                   'Conj: A=1, B=1, | E=0',
                   'Conj: A=1, B=0, | E=0',
                   'Conj: A=0, B=1, | E=0',
                   'Conj: A=0, B=0, | E=0')

# They follow the order:
# c1: 000 
# c2: 010
# c3: 100
# c4: 110
# c5: 111
# d1: 000
# d2: 010
# d3: 011
# d4: 100
# d5: 101
# d6: 110
# d7: 111

# Which can conveniently is alphanumeric and be mapped using unique vals from the trialtype factor
trialvalsvec <- as.vector(levels(mp$trialtype)) %>% sort(decreasing = TRUE)
```

## Model predictions are made up of...
Weighted averages of each probability group - here is group 1

```{r, echo=FALSE, warning=FALSE}
p71 <- modelNorm5 %>% 
  filter(pgroup == '1') %>% 
  drop_na() %>% 
  ggplot(aes(x = node3, y = forplot,
                      fill = node3)) +
  geom_col(aes(x = node3, y = wa2), alpha = 0.4) +
  facet_wrap(factor(trialtype, levels = trialvalsvec, labels = fulltrialspec)~.) +  #, scales='free_x'
  geom_point(aes(colour=uAuB, shape=uAuB), size=3) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
  labs(x='Node', y='Effect size', fill='Weighted average \neffect size', 
       shape='Assuming unobserved \nvariables are...', 
       colour='Assuming unobserved \nvariables are...',
       title = 'Weighted average for model prediction for pgroup 1')
       

p71
```

Weighted averages of each probability group - here is group 2

```{r, echo=FALSE, warning=FALSE}
p72 <- modelNorm5 %>% 
  filter(pgroup == '2') %>% 
  drop_na() %>% 
  ggplot(aes(x = node3, y = forplot,
                      fill = node3)) +
  geom_col(aes(x = node3, y = wa2), alpha = 0.4) +
  facet_wrap(factor(trialtype, levels = trialvalsvec, labels = fulltrialspec)~.) +  #, scales='free_x'
  geom_point(aes(colour=uAuB, shape=uAuB), size=3) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
  labs(x='Node', y='Effect size', fill='Weighted average \neffect size', 
       shape='Assuming unobserved \nvariables are...', 
       colour='Assuming unobserved \nvariables are...',
       title = 'Weighted average for model prediction for pgroup 2')
       

p72
```

Weighted averages of each probability group - here is group 3

```{r, echo=FALSE, warning=FALSE}
p73 <- modelNorm5 %>% 
  filter(pgroup == '1') %>% 
  drop_na() %>% 
  ggplot(aes(x = node3, y = forplot,
                      fill = node3)) +
  geom_col(aes(x = node3, y = wa2), alpha = 0.4) +
  facet_wrap(factor(trialtype, levels = trialvalsvec, labels = fulltrialspec)~.) +  #, scales='free_x'
  geom_point(aes(colour=uAuB, shape=uAuB), size=3) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
  labs(x='Node', y='Effect size', fill='Weighted average \neffect size', 
       shape='Assuming unobserved \nvariables are...', 
       colour='Assuming unobserved \nvariables are...',
       title = 'Weighted average for model prediction for pgroup 3')
       

p73
```



## All probgroups
Shown next to each other with position dodge - don't like it much
```{r, echo=FALSE, warning=FALSE}
p6 <- combNorm %>% 
  arrange(node3) %>% group_by(trialtype) %>% mutate(perms=6/sum(isPerm==TRUE)) %>% # This bit sets a new var to get the abline
  ggplot(aes(x = node3, y = percent,
             fill = pgroup, alpha = isPerm)) + # Alpha shading shows what is a coherent answer
  scale_alpha_discrete(range = c(0.3, 0.9), guide = guide_legend(override.aes = list(fill = "black"))) +
  facet_wrap(factor(trialtype, levels = trialvalsvec, labels = fulltrialspec)~.) + 
  # Add a roving baseline for chance choice of permissable answer values (ie. the fully shaded ones)
  geom_hline(aes(yintercept = perms), colour='red', linetype='dashed') + 
  # Now add baseline for chance choice of any node, ie. 1/8 = .125
  geom_hline(aes(yintercept = 0.125), colour='blue', linetype='dotted') + 
  #geom_col(data = filter(combNorm, name=='ppts' & pgroup=='1')) +
  geom_col(data = filter(combNorm, name=='ppts'),
           aes(fill = pgroup), position = 'dodge') +
  new_scale_color() +
  geom_point(data = filter(combNorm, name=='cesm' ), #& pgroup=='1'
             aes(shape = realLat, colour = realLat), size=2) + 
  scale_color_brewer(name=waiver(), palette = 'Dark2', direction = -1) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  guides(fill = guide_legend(override.aes = list(size = 0))) +
  labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants', 
       title = 'All 3 parameter groups side by side',
       subtitle = 'Participant choice (bars) against weighted average \nCESM model prediction (dots)')

p6

```

## Model predictions compared against participant data, split out by probability group

The first plot is probability group 1

```{r, echo=FALSE, warning=FALSE}
# For plotting we need two colour scales so used package from https://eliocamp.github.io/ggnewscale/
#library(ggnewscale) 

# Probgroup 1 - the basic one, 12 facets
p1 <- combNorm %>% 
  filter(pgroup == '1') %>% 
  arrange(node3) %>% group_by(trialtype) %>% mutate(perms=2/sum(isPerm==TRUE)) %>% # This bit sets a new var to get the abline
  ggplot(aes(x = node3, y = percent,
                     fill = node3, alpha = isPerm)) + # Alpha shading shows what is a coherent answer
  scale_alpha_discrete(range = c(0.3, 0.9), guide = guide_legend(override.aes = list(fill = "black"))) +
  facet_wrap(factor(trialtype, levels = trialvalsvec, labels = fulltrialspec)~.) + 
  # Add a roving baseline for chance choice of permissable answer values (ie. the fully shaded ones)
  geom_hline(aes(yintercept = perms), colour='red', linetype='dashed') + 
  # Now add baseline for chance choice of any node, ie. 1/8 = .125
  geom_hline(aes(yintercept = 0.125), colour='blue', linetype='dotted') + 
  geom_col(data = filter(combNorm, name=='ppts' & pgroup=='1')) +
  new_scale_color() +
  geom_point(data = filter(combNorm, name=='cesm' & pgroup=='1'), 
             aes(shape = realLat, colour = realLat), size=2) + 
  scale_color_brewer(name=waiver(), palette = 'Dark2', direction = -1) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  guides(fill = guide_legend(override.aes = list(size = 0))) +
  labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants', 
       title = 'Parameter group 1) .1, .5, .8, .5',
       subtitle = 'Participant choice (bars) against weighted average \nCESM model prediction (dots)')

p1

cchart <- paste0('~/Documents/GitHub/gw/Collider/figs/model_preds/','pg1s',params$stab,'.pdf')
ggsave(cchart, plot=p1, width = 7, height = 5, units = 'in')

```

The second is probability group 2.

```{r, echo=FALSE, warning=FALSE}
# For plotting we need two colour scales so used package from https://eliocamp.github.io/ggnewscale/
#library(ggnewscale) 

# Probgroup 2 - the basic one, 12 facets
p2 <- combNorm %>% 
  filter(pgroup == '2') %>% 
  arrange(node3) %>% group_by(trialtype) %>% mutate(perms=2/sum(isPerm==TRUE)) %>% # This bit sets a new var to get the abline
  ggplot(aes(x = node3, y = percent,
                     fill = node3, alpha = isPerm)) + # Alpha shading shows what is a coherent answer
  scale_alpha_discrete(range = c(0.3, 0.9), guide = guide_legend(override.aes = list(fill = "black"))) +
  facet_wrap(factor(trialtype, levels = trialvalsvec, labels = fulltrialspec)~.) + 
  # Add a roving baseline for chance choice of permissable answer values (ie. the fully shaded ones)
  geom_hline(aes(yintercept = perms), colour='red', linetype='dashed') + 
  # Now add baseline for chance choice of any node, ie. 1/8 = .125
  geom_hline(aes(yintercept = 0.125), colour='blue', linetype='dotted') + 
  geom_col(data = filter(combNorm, name=='ppts' & pgroup=='2')) +
  new_scale_color() +
  geom_point(data = filter(combNorm, name=='cesm' & pgroup=='2'), 
             aes(shape = realLat, colour = realLat), size=2) + 
  scale_color_brewer(name=waiver(), palette = 'Dark2', direction = -1) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  guides(fill = guide_legend(override.aes = list(size = 0))) +
  labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants', 
       title = 'Parameter group 2) .5, .1, .5, .8',
       subtitle = 'Participant choice (bars) against weighted average \nCESM model prediction (dots)')

p2

cchart <- paste0('~/Documents/GitHub/gw/Collider/figs/model_preds/','pg2s',params$stab,'.pdf')
ggsave(cchart, plot=p2, width = 7, height = 5, units = 'in')

```

Now for probability group 3.

```{r, echo=FALSE, warning=FALSE}
# Probgroup 3 - the basic one, 12 facets
p3 <- combNorm %>% 
  filter(pgroup == '3') %>% 
  arrange(node3) %>% group_by(trialtype) %>% mutate(perms=2/sum(isPerm==TRUE)) %>% # This bit sets a new var to get the abline
  ggplot(aes(x = node3, y = percent,
                     fill = node3, alpha = isPerm)) + # Alpha shading shows what is a coherent answer
  scale_alpha_discrete(range = c(0.3, 0.9), guide = guide_legend(override.aes = list(fill = "black"))) +
  facet_wrap(factor(trialtype, levels = trialvalsvec, labels = fulltrialspec)~.) + 
  # Add a roving baseline for chance choice of permissable answer values (ie. the fully shaded ones)
  geom_hline(aes(yintercept = perms), colour='red', linetype='dashed') + 
  # Now add baseline for chance choice of any node, ie. 1/8 = .125
  geom_hline(aes(yintercept = 0.125), colour='blue', linetype='dotted') + 
  geom_col(data = filter(combNorm, name=='ppts' & pgroup=='3')) +
  new_scale_color() +
  geom_point(data = filter(combNorm, name=='cesm' & pgroup=='3'), 
             aes(shape = realLat, colour = realLat), size=2) + 
  scale_color_brewer(name=waiver(), palette = 'Dark2', direction = -1) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  guides(fill = guide_legend(override.aes = list(size = 0))) +
  labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants', 
       title = 'Parameter group 3) .1, .7, .8, .5',
       subtitle = 'Participant choice (bars) against weighted average \nCESM model prediction (dots)')

p3

cchart <- paste0('~/Documents/GitHub/gw/Collider/figs/model_preds/','pg3s',params$stab,'.pdf')
ggsave(cchart, plot=p3, width = 7, height = 5, units = 'in')

```

## Correlations

We want to check whether people's judgements are less sensitive to the changing probs (param manipulation) than the model is? check statistically through cor(cond1-cond2) for ppts then model, then cor(cond2-3), then 1-3.

```{r}
# Correlations
ppt1 <- dataNorm %>% filter(pgroup==1)
ppt2 <- dataNorm %>% filter(pgroup==2)
ppt3 <- dataNorm %>% filter(pgroup==3)

mod1 <- modelNorm %>% filter(pgroup==1)
mod2 <- modelNorm %>% filter(pgroup==2)
mod3 <- modelNorm %>% filter(pgroup==3)

ppt12cor <- signif(cor(ppt1$prop, ppt2$prop), digits = 3)
ppt13cor <- signif(cor(ppt1$prop, ppt3$prop), digits = 3)
ppt23cor <- signif(cor(ppt2$prop, ppt3$prop), digits = 3)

mod12cor <- signif(cor(mod1$normpred, mod2$normpred), digits = 3)
mod13cor <- signif(cor(mod1$normpred, mod3$normpred), digits = 3)
mod23cor <- signif(cor(mod2$normpred, mod3$normpred), digits = 3)
```

### Participants
Across the three parameter groups, the correlations for participants are:
Group 1 to 2: `r toString(ppt12cor)`.
Group 1 to 3: `r toString(ppt13cor)`.
Group 2 to 3: `r toString(ppt23cor)`.

### Model
Across the three parameter groups, the correlations for model are:
Group 1 to 2: `r toString(mod12cor)`.
Group 1 to 3: `r toString(mod13cor)`.
Group 2 to 3: `r toString(mod23cor)`.

## Correlation to check model fit

This scatter plot is for all three probability settings, for just this value of s.

```{r, echo=FALSE}
# Scatter of correlation
scatter <- ggplot(combNorm2, aes(x = ppts, y = cesm, shape = node3, color = trialtype)) +
  scale_shape_manual(values = 18:25) +
  geom_point(size=2) + # aes(shape = node3, color = trialtype)
  theme_bw() +
  guides(shape = guide_legend(override.aes = list(size = 5) ) ) # Makes key symbols bigger

scatter

```

Then the important number is `r signif(cor(combNorm2$ppts, combNorm2$cesm), digits=3)`.

Let's also split them out by probgroups...

### Parameter group 1) .1, .5, .8, .5.

```{r, echo=FALSE}
# Scatter of correlation
scatter1 <- combNorm2 %>% 
  filter(pgroup == '1') %>% 
  ggplot(aes(x = ppts, y = cesm, shape = node3, color = trialtype)) +
  scale_shape_manual(values = 18:25) +
  geom_point(size=2) + # aes(shape = node3, color = trialtype)
  theme_bw() +
  guides(shape = guide_legend(override.aes = list(size = 5) ) ) # Makes key symbols bigger

scatter1

combNorm21 <- combNorm2 %>% filter(pgroup==1) 
corval1 <- signif(cor(combNorm21$ppts, combNorm21$cesm), digits=3)
```

The correlation is `r toString(corval1)`.

### Parameter group 2) .5, .1, .5, .8.

```{r, echo=FALSE}
scatter2 <- combNorm2 %>% 
  filter(pgroup == '2') %>% 
  ggplot(aes(x = ppts, y = cesm, shape = node3, color = trialtype)) +
  scale_shape_manual(values = 18:25) +
  geom_point(size=2) + # aes(shape = node3, color = trialtype)
  theme_bw() +
  guides(shape = guide_legend(override.aes = list(size = 5) ) ) # Makes key symbols bigger

scatter2

combNorm22 <- combNorm2 %>% filter(pgroup==2) 
corval2 <- signif(cor(combNorm22$ppts, combNorm22$cesm), digits=3)
```

The correlation is `r toString(corval2)`.

### Parameter group 3) .1, .7, .8, .5.

```{r, echo=FALSE}
scatter3 <- combNorm2 %>% 
  filter(pgroup == '3') %>% 
  ggplot(aes(x = ppts, y = cesm, shape = node3, color = trialtype)) +
  scale_shape_manual(values = 18:25) +
  geom_point(size=2) + # aes(shape = node3, color = trialtype)
  theme_bw() +
  guides(shape = guide_legend(override.aes = list(size = 5) ) ) # Makes key symbols bigger

scatter3

combNorm23 <- combNorm2 %>% filter(pgroup==3) 
corval3 <- signif(cor(combNorm23$ppts, combNorm23$cesm), digits=3)

cors <- c(corval1, corval2, corval3)
meancor <- mean(x = cors)

```

The correlation is `r toString(corval3)`.

Thus the average correlation across the three probability groups is `r toString(meancor)`