# --------- Get the first five pilot data -------------
pilot5 <- read.csv('../processed_data/pilot1.csv') %>% select(-1)
# Put them together
dataset <- rbind(pilot5,dataset,dataset2)
# ---------- Now analysing all data together ---------
# 6950 obs of 15
# Remove empty cols and rows
dataset <- dataset %>% select(-c(13:14))
dataset <- dataset %>% filter(cb!='NA') # Obs should be 12* no. of ppts, as each did 12 trials. 3509 of 13
# Here 3329 of 13 vars, so some did not complete. Find who is complete
s12 <- dataset %>% group_by(subject_id) %>% summarise(n=n())
# Remove these ones
rem <- filter(s12,n!=12) # 15 were removed, although maybe keep the ones with 11?
data <- dataset %>% filter(!(subject_id %in% rem$subject_id)) # leaves 3456 obs, ie from 288 ppts
# REMEMBER TO TURN ROUND THE CB ONES where cb==0 probs are 1,2,3,4 but cb==1 are 3,4,1,2
# IF WE DECIDE WE NEED IT - WE MIGHT NOT ACTUALLY - DEPENDS HOW TO COMPARE AGAINST PROBS
data <- data %>% mutate(probgroup = if_else(prob0=='10%' & prob1=='50%' | prob2=='10%' & prob3=='50%', '1',
if_else(prob0=='50%' & prob1=='80%' | prob2=='50%' & prob3=='80%', '2', '3')))
# Now reattach the number of their answer, as atm it has only recorded the text on their radio button
# First here are the arrays of possible buttons from js exp.
jobanswers <- c('The candidate had skill A',
'The candidate did not have skill A',
'The candidate demonstrated skill A',
'The candidate did not demonstrate skill A',
'The candidate had skill B',
'The candidate did not have skill B',
'The candidate demonstrated skill B',
'The candidate did not demonstrate skill B')
cookanswers <- c('The chef completed the main dish',
'The chef did not complete the main dish',
'The main dish impressed the panel',
'The main dish did not impress the panel',
'The chef completed the dessert',
'The chef did not complete the dessert',
'The dessert impressed the panel',
'The dessert did not impress the panel')
groupanswers <- c('The lecturer attended',
'The lecturer did not attend',
'The lecturer talked about the paper',
'The lecturer did not talk about the paper',
'The postdoc attended',
'The postdoc did not attend',
'The postdoc talked about the paper',
'The postdoc did not talk about the paper')
# Now make a new column with the position in array of their answer
data <- data %>% mutate(ans = if_else(scenario=='job', match(data$answer, jobanswers),
if_else(scenario=='cook', match(data$answer, cookanswers),
match(data$answer, groupanswers))))
# -------- Permissable actual cause analysis -----------
# Checks whether ppt's answers are permissable as per Tadeg's actual causation condition
# This is separate from the counterbalanced issue, so can be done on the un-switched vars
# Then analyses by participant
# Get .possAns out of json
js <- worldsdf %>% select(ends_with("possAns"))
# Remove .possAns string from colnames, transpose so easier to search and add 1 to every cell because js indexes from 0
colnames(js) <- sub(".possAns", "", colnames(js))
js <- t(js)
js <- js+1 # now it ranges 1:8 instead of 0:7
# Empty vec to put the answers in, same order and size as
isPerm <- rep(NA, 3456)
# (Long winded index match - would be good to know a better way)
for (k in 1:nrow(data))
{
row <- data[k,]
ttype <- row$trialtype
ans <- row$ans
jsvec <- js[ttype,1:8]
isposs <- ans %in% jsvec
isPerm[k] <- isposs
}
# Add to df1 (I checked it is right)
data <- cbind(data, isPerm)
# Now group by ppt to see if they mostly pick permissable answers
tf <- data %>% group_by(subject_id, isPerm) %>% summarise(n=n())
# There is a problem: as counterbalancing happened across the probability vectors
# (ie cb==0 had var 'A' as one prob, and cb==1 had it the other)
# We can reverse that by when cb==1 & ans was A, add 4 to ans
# and when cb==0 and ans was B, subtract 4 from ans
# Store indices of which ansers are already a and which are b
aans <- as.vector(1:4)
bans <- as.vector(5:8)
data <- data %>% mutate(anscb = if_else(cb==1 & ans %in% aans, ans+4,
if_else(cb==1 & ans %in% bans, ans-4, ans)))
# Map the answers they gave to the variables
# PROBLEM - WHAT TO DO ABOUT THE CB PROBS
data <- data %>% mutate(ansVar = if_else(anscb==1|anscb==2, 'A',
if_else(anscb==3|anscb==4, 'Au',
if_else(anscb==5|anscb==6, 'B', 'Bu'))))
data <- data %>% mutate(ansVar2 = if_else(anscb==1|anscb==2, 'A',
if_else(anscb==3, 'Au=1',
if_else(anscb==4, 'Au=0',
if_else(anscb==5|anscb==6, 'B',
if_else(anscb==7, 'Bu=1', 'Bu=0'))))))
data <- data %>% mutate(ansVar3 = if_else(anscb==1, 'A=1',
if_else(anscb==2, 'A=0',
if_else(anscb==3, 'Au=1',
if_else(anscb==4, 'Au=0',
if_else(anscb==5, 'B=1',
if_else(anscb==6, 'B=0',
if_else(anscb==7, 'Bu=1', 'Bu=0'))))))))
# Split them by probgroup here, so they can go against the relevant model pred group for comparison
pg1 <- data %>% filter(probgroup==1) # 1121 obs of 19
pg2 <- data %>% filter(probgroup==2) # 1104 obs of 19
pg3 <- data %>% filter(probgroup==3) # 1051 obs of 19
# Now summarise. For first round of plots , do ansVar=8 to see everything, so ansVar3
# If want A=a, or just 'A', take ansVar2 later
pg1prop <- pg1 %>% group_by(trialtype, ansVar3) %>% summarise(n=n()) %>% mutate(prop = n/sum(n))
pg2prop <- pg2 %>% group_by(trialtype, ansVar3) %>% summarise(n=n()) %>% mutate(prop = n/sum(n))
pg3prop <- pg3 %>% group_by(trialtype, ansVar3) %>% summarise(n=n()) %>% mutate(prop = n/sum(n))
# Now save
save(data, pg1, pg2, pg3, pg1prop, pg2prop, pg3prop, file="../Data/Data.Rdata")
View(data)
View(pg1prop)
getwd()
# Setwd - it might still be in the previous script's one
# (which it needed there to use a nifty one line to get the data docs out and together)
# so now do
setwd("../Main_scripts")
getwd()
# Read in processed ppt data
load('../Data/Data.Rdata', verbose = T)
# Read in model preds # see master script for indexing etc -- if change what is saved in masterscript, it'll affect here
load('../model_data/modpreds.rdata', verbose = T) # list of 3
modpredsc <- mod_preds[[1]][[2]] # 64 obs of 18
modpredsd <-mod_preds[[1]][[1]]
# Or maybe don't need, if plotting before could use multiple dfs at a time, just substitute in
wad <- as.data.frame(modpredsd %>% group_by(trialtype,node3) %>% summarise(predicted = sum(wa)))
wac <- as.data.frame(modpredsc %>% group_by(trialtype,node3) %>% summarise(predicted = sum(wa)))
# Gah need it the same name as the column
pg1prop <- pg1prop %>% rename(node3 = ansVar3)
pg2prop <- pg2prop %>% rename(node3 = ansVar3)
pg3prop <- pg3prop %>% rename(node3 = ansVar3)
# Split out the 'proportion' dfs into conjunctive and disjucntive
pg1c <- pg1prop %>% filter(grepl("^c", trialtype)) # 16 of 4
pg1d <- pg1prop %>% filter(grepl("^d", trialtype)) # 19 obs of 4
pg2c <- pg2prop %>% filter(grepl("^c", trialtype)) # 11 of 4
pg2d <- pg2prop %>% filter(grepl("^d", trialtype)) # 14 of 4
pg3c <- pg3prop %>% filter(grepl("^c", trialtype)) # 13 obs of 4
pg3d <- pg3prop %>% filter(grepl("^d", trialtype)) # 19 obs of 4
# Now we need the vectors of all the node values and trialtypes (c and d)
# (so the columns can be there even when empty, for the chart we want)
nodevals <- as.data.frame(unique(modpredsc$node3))
names(nodevals) <- 'node3'
trialvalsc <- as.data.frame(unique(modpredsc$trialtype))
names(trialvalsc) <- 'trialtype'
trialvalsd <- as.data.frame(unique(modpredsd$trialtype))
names(trialvalsd) <- 'trialtype'
trialvalscvec <- as.vector(unique(modpredsc$trialtype))
fulltrialspecc <- c('A=0, B=0, | E=0','A=0, B=1, | E=0','A=1, B=0, | E=0','A=1, B=1, | E=0','A=1, B=1, | E=1')
# Some 'intermediate merges'
# First, all trials and nodes for c and for d
emptyc <- merge(trialvalsc, nodevals)
emptyd <- merge(trialvalsd, nodevals)
# Then merge in the values of probability group 1 (need to do this for all probability groups)
emptypgc1 <- merge(emptyc, pg1c, all.x = T) %>% replace(is.na(.), 0)
emptypgc2 <- merge(emptyc, pg2c, all.x = T) %>% replace(is.na(.), 0)
emptypgc3 <- merge(emptyc, pg3c, all.x = T) %>% replace(is.na(.), 0)
emptypgd1 <- merge(emptyd, pg1d, all.x = T) %>% replace(is.na(.), 0)
emptypgd2 <- merge(emptyd, pg2d, all.x = T) %>% replace(is.na(.), 0)
emptypgd3 <- merge(emptyd, pg3d, all.x = T) %>% replace(is.na(.), 0)
# Then merge in the weighted average ('wa') model preds
fp1c <- merge(x = emptypgc1, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp2c <- merge(x = emptypgc2, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp3c <- merge(x = emptypgc3, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp1d <- merge(x = emptypgd1, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp2d <- merge(x = emptypgd2, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp3d <- merge(x = emptypgd3, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
p1c <- ggplot(fp1c, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalscvec, labels = fulltrialspecc)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by % of \nparticipants',
title = 'Conjunctive collider: participant choice (bars) against \nweighted average CESM model prediction (dots) \n \nGroup 1:'
)
p1c
p1d <- ggplot(fp1d, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalscvec, labels = fulltrialspecc)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by % of \nparticipants',
title = 'Conjunctive collider: participant choice (bars) against \nweighted average CESM model prediction (dots) \n \nGroup 1:'
)
p1d
View(fp1d)
View(fp2c)
View(fp2d)
View(fp3c)
View(fp3d)
View(trialvalsd)
View(pg3d)
View(emptypgd2)
fp1d <- merge(x = emptypgd1, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp2d <- merge(x = emptypgd2, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp3d <- merge(x = emptypgd3, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fulltrialspecd <- c('A=0, B=0, | E=0','A=0, B=1, | E=0','A=0, B=1, | E=1', 'A=1, B=0, | E=0','A=1, B=1, | E=0','A=1, B=0, | E=1', 'A=1, B=1, | E=1')
fp1d <- merge(x = emptypgd1, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp2d <- merge(x = emptypgd2, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp3d <- merge(x = emptypgd3, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
p1d <- ggplot(fp1d, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalsdvec, labels = fulltrialspecd)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by % of \nparticipants',
title = 'Conjunctive collider: participant choice (bars) against \nweighted average CESM model prediction (dots) \n \nGroup 1:'
)
p1d
trialvalsdvec <- as.vector(unique(modpredsd$trialtype))
p1d <- ggplot(fp1d, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalsdvec, labels = fulltrialspecd)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by % of \nparticipants',
title = 'Conjunctive collider: participant choice (bars) against \nweighted average CESM model prediction (dots) \n \nGroup 1:'
)
p1d
plot_to_ppt_d <- function(df) {
ggplot(df, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalsdvec, labels = fulltrialspecd)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants',
title = paste0('Disjunctive collider: pA=',poss_params[[i]][1,2],', pAu=',poss_params[[i]][2,2],
', pB=',poss_params[[i]][3,2], ', pBu=',poss_params[[i]][4,2]),
subtitle = 'Participant choice (bars) against weighted average CESM model prediction (dots)')
)
plot_to_ppt_d <- function(df) {
ggplot(df, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalsdvec, labels = fulltrialspecd)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants',
title = paste0('Disjunctive collider: pA=',poss_params[[i]][1,2],', pAu=',poss_params[[i]][2,2],
', pB=',poss_params[[i]][3,2], ', pBu=',poss_params[[i]][4,2]),
subtitle = 'Participant choice (bars) against weighted average CESM model prediction (dots)')
}
plot_to_ppt_d <- function(df) {
pd <- ggplot(df, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalsdvec, labels = fulltrialspecd)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants',
title = paste0('Disjunctive collider: pA=',poss_params[[i]][1,2],', pAu=',poss_params[[i]][2,2],
', pB=',poss_params[[i]][3,2], ', pBu=',poss_params[[i]][4,2]),
subtitle = 'Participant choice (bars) against weighted average CESM model prediction (dots)')
pd
}
plot_to_ppt_d(fp1d)
#------- 1. Create parameters, run cesm, get model predictions and save them ------------
# All the params we want, put into a list of 4x2 dfs
params1 <- data.frame("0"=c(0.9,0.5,0.2,0.5), "1"=c(0.1,0.5,0.8,0.5))
params2 <- data.frame("0"=c(0.5,0.9,0.5,0.2), "1"=c(0.5,0.1,0.5,0.8))
params3 <- data.frame("0"=c(0.9,0.3,0.2,0.5), "1"=c(0.1,0.7,0.8,0.5))
row.names(params1) <- row.names(params2) <- row.names(params3) <-c ("pA",  "peA", "pB", "peB")
names(params1) <- names(params2) <- names(params3) <- c('0','1')
poss_params <- list(params1, params2, params3)
plot_to_ppt_d(fp1d)
i <- 1
plot_to_ppt_d(fp1d)
plot_to_ppt_d <- function(df) {
pd <- ggplot(df, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalsdvec, labels = fulltrialspecd)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants',
title = paste0('Disjunctive collider: pA=',poss_params[[i]][1,2],', pAu=',poss_params[[i]][2,2],
', pB=',poss_params[[i]][3,2], ', pBu=',poss_params[[i]][4,2]),
subtitle = 'Participant choice (bars) against weighted average \nCESM model prediction (dots)')
pd
}
plot_to_ppt_c <- function(df) {
pc <- ggplot(df, aes(x = node3, y = prop,
fill = node3)) +
geom_col(aes(x = node3, y = prop), alpha = 0.4) +
facet_wrap(factor(trialtype, levels = trialvalscvec, labels = fulltrialspecc)~.) + #, scales='free_x'
geom_point(aes(x = node3, y = pred), size=2, alpha=0.4) + # pch=21 matches point to bar
theme_classic() +
theme(axis.text.x = element_text(angle = 90)) +
guides(fill = guide_legend(override.aes = list(size = 0, alpha=0.4))) +
labs(x='Node', y=NULL, fill='Explanation \nselected as \nbest by y% of \nparticipants',
title = paste0('Conjunctive collider: pA=',poss_params[[i]][1,2],', pAu=',poss_params[[i]][2,2],
', pB=',poss_params[[i]][3,2], ', pBu=',poss_params[[i]][4,2]),
subtitle = 'Participant choice (bars) against weighted average \nCESM model prediction (dots)')
pc
}
plot_to_ppt_c(fp3c)
##############################################################
#### Master script for collider within gridworld project #####
##############################################################
#library(tidyverse)
rm(list=ls())
#------- 1. Create parameters, run cesm, get model predictions and save them ------------
# All the params we want, put into a list of 4x2 dfs
params1 <- data.frame("0"=c(0.9,0.5,0.2,0.5), "1"=c(0.1,0.5,0.8,0.5))
params2 <- data.frame("0"=c(0.5,0.9,0.5,0.2), "1"=c(0.5,0.1,0.5,0.8))
params3 <- data.frame("0"=c(0.9,0.3,0.2,0.5), "1"=c(0.1,0.7,0.8,0.5))
row.names(params1) <- row.names(params2) <- row.names(params3) <-c ("pA",  "peA", "pB", "peB")
names(params1) <- names(params2) <- names(params3) <- c('0','1')
poss_params <- list(params1, params2, params3)
mod_preds <- vector(mode='list', length=3)
# NOTE - RUN THIS AGAIN FOR REAL
# Loop through the list of param dfs and run a series of scripts, to generate worlds, calculate model preds and plot
for (i in 1:length(poss_params)) {
source('general_cesm_a.R')
# Script contains functions, but we need to explicitly call them as dfs which will be used throughout
dfd <- world_combos(params = poss_params[[i]], structure = 'disjunctive')
dfc <- world_combos(params = poss_params[[i]], structure = 'conjunctive')
mp1d <- generic_cesm(params = poss_params[[i]], df = dfd)
mp1c <- generic_cesm(params = poss_params[[i]], df = dfc)
# Let's save these if we need to. This works but need a better structure
#mod_preds[[i]][[1]] <- dfd # PROB. NOT NEEDED
#mod_preds[[i]][[2]] <- dfc
#mod_preds[[1]][[i]]$dfc <- dfc
# The next script makes dfs forplotd,forplotc, with model preds used for plotting
source('unobs_a.R')
# Save them too, for later
mod_preds[[i]][[1]] <- forplotd
mod_preds[[i]][[2]] <- forplotc
#mod_preds[[i]][[5]] <- wad # If you change what is taken here, it will change the indexing position later
#mod_preds[[i]][[6]] <- wac
source('collider_plot_a.R')
# One way of charting the possible values of the unobserved variables, saved under `i`
# eg 'da1' is disjunctive actual , params setting 1
dchart <- paste0('~/Documents/GitHub/gw/Collider/figs/model_preds/','da',i,'.pdf')
ggsave(dchart, plot=pd, width = 7, height = 5, units = 'in')
cchart <- paste0('~/Documents/GitHub/gw/Collider/figs/model_preds/','ca',i,'.pdf')
ggsave(cchart, plot=pc, width = 7, height = 5, units = 'in')
# Important to find the right piece of the model predictions - what do we want to do with it?
# assuming wa (in unobs_a, saved as wad/wac)
}
# Save
save(mod_preds, file='../model_data/modpreds.Rdata')
#--------------- 2. Get ppt data  -------------------
source('mainbatch_preprocessing.R') # saves data
source('collider_analysis.R') # combine with model predictions
##############################################################
#### Master script for collider within gridworld project #####
##############################################################
#library(tidyverse)
rm(list=ls())
#------- 1. Create parameters, run cesm, get model predictions and save them ------------
source('get_model_preds.R')
setwd("/Users/stephaniedroop/Documents/GitHub/gw/Collider/Main_scripts")
##############################################################
#### Master script for collider within gridworld project #####
##############################################################
# setwd("/Users/stephaniedroop/Documents/GitHub/gw/Collider/Main_scripts")
#library(tidyverse)
rm(list=ls())
#------- 1. Create parameters, run cesm, get model predictions and save them ------------
source('get_model_preds.R')
#--------------- 2. Get ppt data  -------------------
source('mainbatch_preprocessing.R') # saves data
# Setwd back again - it might still be in the previous script's one
# (which it needed there to use a nifty one line to get the data docs out and together)
setwd("../Main_scripts")
source('collider_analysis.R') # combine with model predictions
# --------------- 3. Now plot --------------
source('plot_model_to_ppt.R')
i <- 1
toplotd <- paste0('fp',i,'d')
# --------------- 3. Now plot --------------
source('plot_model_to_ppt.R')
# --------------- 3. Now plot --------------
source('plot_model_to_ppt.R')
# --------------- 3. Now plot --------------
source('plot_model_to_ppt.R')
# --------------- 3. Now plot --------------
source('plot_model_to_ppt.R')
source('collider_analysis.R') # combine with model predictions
# --------------- 3. Now plot --------------
source('plot_model_to_ppt.R')
####################################################
###### Collider analysis - compare model preds #####
####################################################
# Script takes the processed data from the collider ppt expt
# (which was cleaned and sliced in `mainbatch_preprocessing.R`)
# and combining with model predictions, and visualising
# library(tidyverse)
rm(list=ls())
# Read in processed ppt data
load('../Data/Data.Rdata', verbose = T)
# Read in model preds # see master script for indexing etc -- if change what is saved in masterscript, it'll affect here
load('../model_data/modpreds.rdata', verbose = T) # list of 3
modpredsc <- mod_preds[[1]][[2]] # 64 obs of 18
modpredsd <-mod_preds[[1]][[1]]
# Or maybe don't need, if plotting before could use multiple dfs at a time, just substitute in
wad <- as.data.frame(modpredsd %>% group_by(trialtype,node3) %>% summarise(predicted = sum(wa)))
wac <- as.data.frame(modpredsc %>% group_by(trialtype,node3) %>% summarise(predicted = sum(wa)))
# Gah need it the same name as the column
pg1prop <- pg1prop %>% rename(node3 = ansVar3)
pg2prop <- pg2prop %>% rename(node3 = ansVar3)
pg3prop <- pg3prop %>% rename(node3 = ansVar3)
# Split out the 'proportion' dfs into conjunctive and disjucntive
pg1c <- pg1prop %>% filter(grepl("^c", trialtype)) # 16 of 4
pg1d <- pg1prop %>% filter(grepl("^d", trialtype)) # 19 obs of 4
pg2c <- pg2prop %>% filter(grepl("^c", trialtype)) # 11 of 4
pg2d <- pg2prop %>% filter(grepl("^d", trialtype)) # 14 of 4
pg3c <- pg3prop %>% filter(grepl("^c", trialtype)) # 13 obs of 4
pg3d <- pg3prop %>% filter(grepl("^d", trialtype)) # 19 obs of 4
# Now we need the vectors of all the node values and trialtypes (c and d)
# (so the columns can be there even when empty, for the chart we want)
nodevals <- as.data.frame(unique(modpredsc$node3))
names(nodevals) <- 'node3'
trialvalsc <- as.data.frame(unique(modpredsc$trialtype))
names(trialvalsc) <- 'trialtype'
trialvalsd <- as.data.frame(unique(modpredsd$trialtype))
names(trialvalsd) <- 'trialtype'
trialvalscvec <- as.vector(unique(modpredsc$trialtype))
fulltrialspecc <- c('A=0, B=0, | E=0','A=0, B=1, | E=0','A=1, B=0, | E=0','A=1, B=1, | E=0','A=1, B=1, | E=1')
trialvalsdvec <- as.vector(unique(modpredsd$trialtype))
fulltrialspecd <- c('A=0, B=0, | E=0','A=0, B=1, | E=0','A=0, B=1, | E=1', 'A=1, B=0, | E=0','A=1, B=1, | E=0','A=1, B=0, | E=1', 'A=1, B=1, | E=1')
# Some 'intermediate merges'
# First, all trials and nodes for c and for d
emptyc <- merge(trialvalsc, nodevals)
emptyd <- merge(trialvalsd, nodevals)
# Then merge in the values of probability group 1 (need to do this for all probability groups)
emptypgc1 <- merge(emptyc, pg1c, all.x = T) %>% replace(is.na(.), 0)
emptypgc2 <- merge(emptyc, pg2c, all.x = T) %>% replace(is.na(.), 0)
emptypgc3 <- merge(emptyc, pg3c, all.x = T) %>% replace(is.na(.), 0)
emptypgd1 <- merge(emptyd, pg1d, all.x = T) %>% replace(is.na(.), 0)
emptypgd2 <- merge(emptyd, pg2d, all.x = T) %>% replace(is.na(.), 0)
emptypgd3 <- merge(emptyd, pg3d, all.x = T) %>% replace(is.na(.), 0)
# Then merge in the weighted average ('wa') model preds
fp1c <- merge(x = emptypgc1, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp2c <- merge(x = emptypgc2, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp3c <- merge(x = emptypgc3, y = wac, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp1d <- merge(x = emptypgd1, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp2d <- merge(x = emptypgd2, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
fp3d <- merge(x = emptypgd3, y = wad, by = c('trialtype', 'node3'), all.x = T) %>% replace(is.na(.), 0) %>% group_by(trialtype) %>% mutate(pred = predicted / sum(predicted))
# That gives us 6 dfs for plotting: probability groups 1:3, for c and for d
# Save
save(file = '../processed_data/fp.rdata', fp1c,fp2c,fp3c,fp1d,fp2d,fp3d, trialvalsdvec,trialvalscvec, fulltrialspecd,fulltrialspecc)
View(pg2prop)
pg2prop %>% sum(n)
View(pg3d)
pg3prop %>% group_by(trialtype) %>% summarise(n=n())
pg3prop %>% group_by(trialtype) %>% summarise(sum=n())
pg3prop %>% group_by(trialtype) %>% summarise(sum=())
pg3prop %>% group_by(trialtype) %>% summarise(count(n)
View(fp3d)
View(fp2c)
# Put all the two threes  fp ('for plotting') back together again
fpd <- rbind(fp1d, fp2d, fp3d)
fpc <- rbind(fp1c, fp2c, fp3c)
View(fpd)
p1 <- ggplot(fpd, aes(x = n, y = pred, shape = trialtype, color = node)) +
geom_point(aes(shape = trialtype, color = node )) +
theme_bw() +
guides(color = guide_legend(override.aes = list(size = 3) ) ) # Makes key symbols bigger
p1
p1 <- ggplot(fpd, aes(x = n, y = pred, shape = trialtype, color = node3)) +
geom_point(aes(shape = trialtype, color = node3)) +
theme_bw() +
guides(color = guide_legend(override.aes = list(size = 3) ) ) # Makes key symbols bigger
p1
p1 <- ggplot(fpd, aes(x = prop, y = pred, shape = trialtype, color = node3)) +
geom_point(aes(shape = trialtype, color = node3)) +
theme_bw() +
guides(color = guide_legend(override.aes = list(size = 3) ) ) # Makes key symbols bigger
p1
p1 <- ggplot(fpd, aes(x = prop, y = pred, shape = trialtype, color = node3)) +
geom_point(aes(shape = trialtype, color = node3)) +
theme_bw() +
guides(color = guide_legend(override.aes = list(size = 6) ) ) # Makes key symbols bigger
p1
p1 <- ggplot(fpd, aes(x = prop, y = pred, shape = trialtype, color = node3)) +
geom_point(aes(shape = trialtype, color = node3)) +
theme_bw() +
guides(color = guide_legend(override.aes = list(size = 8) ) ) # Makes key symbols bigger
p1
p1 <- ggplot(fpd, aes(x = prop, y = pred, shape = trialtype, color = node3)) +
geom_point(aes(shape = trialtype, color = node3)) +
theme_bw() +
guides(shape = guide_legend(override.aes = list(size = 5) ) ) # Makes key symbols bigger
p1
pc <- ggplot(fpc, aes(x = prop, y = pred, shape = trialtype, color = node3)) +
geom_point(aes(shape = trialtype, color = node3)) +
theme_bw() +
guides(shape = guide_legend(override.aes = list(size = 5) ) ) # Makes key symbols bigger
pc
