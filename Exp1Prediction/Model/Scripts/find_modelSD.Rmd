---
title: "find_model"
output: html_document
date: "2025-06-03"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## From Neil's script
Takes `gwdata.csv` which was cleaned and processed in `gw_preprocessing.Rmd`

Got script from Neil, `find_model.R`
The task is to do causal model selection from the participant ratings of likely each situation is.
Participants saw 16 scenarios each (generated by unique combinations of 4 binary variables)
And then rated each of 4 outcomes (generated by 2 binary variables) on a 7-point scale for 1 (not likely) to 7 (likely)

The aim of this script is to copy over Neil's code, understand it, and rework into functions and chunks.

==============================================================================
Path and Destination Choice Model Analysis
==============================================================================
This script analyzes experimental data from a path/destination choice task where
participants rated the likelihood of different routes and destinations based on
various factors:

Variables:
- P (Preference): Whether the person has a food preference (0=Absent, 1=Hotdog)
- K (Knowledge): Whether they know about the hotdog stand (0=No, 1=Yes)
- C (Character): Person's character type (0=Lazy, 1=Sporty)
- S (Start): What's visible at the start (0=See_pizza, 1=See_hotdog)

The script:
1. Loads and preprocesses experimental data
2. Fits causal models to predict path choices (short vs long)
3. Fits causal models to predict destination choices (pizza vs hotdog)
4. Uses model comparison to find the best causal structure
5. Visualizes the results and model predictions

NOTE: There was a mistake before in gwdata where there were 28 0s, affecting 19 rows. These have now been removed, leaving 1421 observations instead of 1440.

```{r}
rm(list=ls())

library(tidyverse)
library(ggplot2)

df <- read.csv('../../Experiment/Data/gwExp1data.Rda') # saved in `gw_preprocessing.Rmd`. 1421 ovs of 28

```

==============================================================================
## Calculate Target Distributions
==============================================================================

Get the complete distribution over all outcomes. 

 
```{r}
# 
td <- df %>% 
  group_by(Situation) %>% 
  summarise(p_short_pizza = mean(p_short_pizza, na.rm=T),
  p_long_pizza = mean(p_long_pizza, na.rm=T),
  p_short_hotdog = mean(p_short_hotdog, na.rm=T),
  p_long_hotdog = mean(p_long_hotdog, na.rm=T)) %>% data.frame()

td <- td[,2:5] # 16 obs of 4

# Calculate marginal probabilities for path and destination
td_path <- (df %>% 
              group_by(Situation) %>% 
              summarise(p_long = mean(p_long, na.rm=T)))$p_long

td_destination <- (df %>% 
                     group_by(Situation) %>% 
                     summarise(p_hotdog = mean(p_hotdog, na.rm=T)))$p_hotdog

```



==============================================================================
## Model Structure Definition
==============================================================================
Define all possible causal structures
Each variable can be:
1: positive influence
0: no influence
-1: negative influence

```{r}
state_names <- c("P", "K", "C", "S", "PK", "PC", "PS", "KC", "KS", "CS")

```


```{r}
# 59049 obs of 10 vars (3^10)
structures <- expand.grid(P = -1:1,
                          K = -1:1,
                          C = -1:1,
                          S = -1:1, 
                          PK = -1:1,
                          PC = -1:1,
                          PS = -1:1,
                          KC = -1:1,
                          KS = -1:1,
                          CS = -1:1)

init_full_par <- list(s = c(P = .5,
                          K = .5,
                          C = .5,
                          S = .5,
                          PK = .5,
                          PC = .5,
                          PS = .5,
                          KC = .5,
                          KS = .5,
                          CS = .5),
                    br = .5, # Base rate
                    tau = 1
)

# Create indexing grid for all possible situations - 16 obs of 4
ix <- expand.grid(S = 0:1, 
                  C = 0:1,
                  K = 0:1,
                  P = 0:1)

# Keep it in same order as rest of code
ix <- ix[, c("P", "K", "C", "S")]
rownames(ix) <- NULL

```

==============================================================================
## Model Prediction Functions
==============================================================================
Predict probabilities for outcomes given a causal structure and parameters

The model uses a noisy-OR/noisy-AND-NOT combination:
- Positive influences combine via noisy-OR
- Negative influences combine via noisy-AND-NOT
- These conbine by NOISY-AND-NOT(NOISY-OR(positive_causes), preventative_causes)
- Final probability is transformed via softmax

@param struct Vector indicating causal influences (-1=negative, 0=none, 1=positive)
@param par List of parameters (strength values and temperature)
@return Vector of probabilities for each situation


```{r}
get_mod_pred <- function(struct, par) {
  # Use the predefined ix (created outside)
  states <- ix
  states$PK <- states$P * states$K
  states$PC <- states$P * states$C
  states$PS <- states$P * states$S
  states$KC <- states$K * states$C
  states$KS <- states$K * states$S
  states$CS <- states$C * states$S

  state_mat <- as.matrix(states[, state_names])
  
  # Precompute indices
  nor_idx <- which(struct == 1)
  nandnot_idx <- which(struct == -1)
  one_minus_s <- 1 - par$s
  
  # Vectorized calculations
  p <- sapply(1:nrow(state_mat), function(i) {
    state <- state_mat[i, ]
    nor <- c(1 - par$br, (one_minus_s[nor_idx] ^ state[nor_idx]))
    nandnot <- (one_minus_s[nandnot_idx] ^ state[nandnot_idx])
    (1 - prod(nor)) * prod(nandnot)
  })
  
  # Softmax
  out <- data.frame(p0 = 1 - p, p1 = p)
  out <- exp(as.matrix(out) / par$tau)
  out <- out / rowSums(out)
  out[, "p1"]
}


```


A new version of wrapper

```{r}
wrapper <- function(par, struct, td) {
  s_vals <- plogis(par[1:10])
  names(s_vals) <- state_names

  br_val <- plogis(par[11])
  tau_val <- exp(par[12])

  input_pars <- list(
    s = s_vals,
    br = br_val,
    tau = tau_val
  )

  model_pred <- get_mod_pred(struct, input_pars)
  model_probs <- cbind(1 - model_pred, model_pred)
  kl_div <- sum(rowSums(td * log(td / model_probs)))

  return(kl_div)
}


```

## Interpretaion of KL divergence 

A note on KL-div:

Small KL (e.g., < 0.01 or < 0.1): Very good fit. The model's predictions are extremely close to the target.

Moderate KL (e.g., 0.1â€“0.5): Decent fit. The model captures the main features, but there are noticeable differences.

Large KL (e.g., > 1): Poor fit. The model and target distributions are quite different; the model is missing key aspects of the data


A function to transform pars
```{r}
transform_params <- function(par) {
  c(plogis(par[1:11]), exp(par[12]))
}
```



```{r}
# Test the wrapper
wrapper(par =  rep(.5,12), struct = unlist(structures[10000,]), td = cbind(1-td_path, td_path))
wrapper(par =  rep(.5,12), struct = unlist(structures[10000,]), td = cbind(1-td_destination, td_destination))

out <- optim(wrapper, par = rep(.5,12), struct = unlist(structures[5,]), td = cbind(1-td_path, td_path))
out 
s <- 58941
out <- optim(wrapper, par = rep(.5,12), struct=unlist(structures[s,]), td = cbind(1-td_destination, td_destination))
out 

tmp <- c(1/(1+exp(-out$par[1:11])),
       exp(out$par[12]))
tmp

transform_params(par = out$par)
wrapper(par =  out$par, struct=unlist(structures[5,]), td = cbind(1-td_path, td_path))
```

Other testing workflow


A helper function for fitting
```{r}
fit_structure <- function(struct_row, td) {
  optim_res <- optim(
    wrapper,
    par = rep(.5, 12),
    struct = unlist(structures[struct_row, ]),
    td = td
  )
  params <- transform_params(optim_res$par)
  c(kl = optim_res$value, setNames(params, c(state_names, "tau")))
}

```

This took c.6 hours:

```{r}
n_structs <- nrow(structures)
fitted_path_mods <- matrix(NA, n_structs, 13)
fitted_destination_mods <- matrix(NA, n_structs, 13)

pb <- txtProgressBar(min = 0, max = n_structs, style = 3)
for (s in 1:n_structs) {
  fitted_path_mods[s, ] <- fit_structure(s, cbind(1 - td_path, td_path))
  fitted_destination_mods[s, ] <- fit_structure(s, cbind(1 - td_destination, td_destination))
  setTxtProgressBar(pb, s)
}
close(pb)
colnames(fitted_path_mods) <- colnames(fitted_destination_mods) <- c("kl", state_names, "br", "tau")
fitted_path_mods <- as.data.frame(fitted_path_mods)
fitted_destination_mods <- as.data.frame(fitted_destination_mods)

# 2 dfs, each of 59049 obs of 13 vars
save(file='fitted_situation_modsSD.rdata', fitted_path_mods, fitted_destination_mods) 
```



```{r}
load('fitted_situation_modsSD.rdata', verbose = 5)


fitted_path_mods$n_edge <- rowSums(structures!=0)
fitted_destination_mods$n_edge <- rowSums(structures!=0)

complexity_penalisation <- 0.002 # just picked! justify by plotting how stable it is at different vals of complexity? TO DO free parameter hand fit.
which.min(fitted_path_mods$kl) # 31717 for first td but redone as 32204
# Make the KL bigger for each edge so to penalise complexity and so avoid saturated fully connected model
bpix <- which.min(fitted_path_mods$kl + fitted_path_mods$n_edge*complexity_penalisation) # 29291
bdix <- which.min(fitted_destination_mods$kl + fitted_destination_mods$n_edge*complexity_penalisation) # 32793



best_path <- structures[bpix,] # 00100-10000
best_path_params <- fitted_path_mods[bpix,]

best_destination <- structures[bdix,] # 1001111100
best_destination_params <- fitted_destination_mods[bdix,]
```

```{r}
# Create the best fitting models for display
tmp <- fitted_path_mods[ which.min(fitted_path_mods$kl),]
fitted_path_params <- list(s = c(P = tmp$P,
                               K = tmp$K,
                               C = tmp$C,
                               S = tmp$S,
                               PK=tmp$PK,
                               PC=tmp$PC,
                               PS=tmp$PS,
                               KC=tmp$KC,
                               KS=tmp$KS,
                               CS=tmp$CS),
                         br = tmp$br,
                         tau = tmp$tau)

tmp <- fitted_destination_mods[ which.min(fitted_destination_mods$kl),]

fitted_destination_params <- list(s = c(P = tmp$P,
                                      K = tmp$K,
                                      C = tmp$C,
                                      S = tmp$S,
                                      PK=tmp$PK,
                                      PC=tmp$PC,
                                      PS=tmp$PS,
                                      KC=tmp$KC,
                                      KS=tmp$KS,
                                      CS=tmp$CS),
                                br = tmp$br,
                                tau = tmp$tau)


mpp <- get_mod_pred(structures[bpix,], fitted_path_params)
mpd <- get_mod_pred(structures[bdix,], fitted_destination_params)

df.m <- data.frame(situation = df$SituationVerbose[1:16], td_path = td_path, td_destination = td_destination, mp_path = mpp, mp_destination = mpd)

write.csv(df.m, 'model.csv') # 16 obs of 5 vars

```

Then later some ggplots and igraph stuff... take to new script and try to replace with ggdag, dagr or dagitty