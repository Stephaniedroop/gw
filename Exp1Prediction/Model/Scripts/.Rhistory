load('../Data/ratingsIntersect.rda', verbose = T)
###############################################################################
##### Merge Gridworld ppt explanations with ratings of those explanations #####
###############################################################################
#library(tidyverse)
rm(list = ls())
# Load the processed data from processData.R - 2040 participant rows and a note of 24 duplicates
load('../../Exp2Explanation/Experiment/processedData.rda', verbose = T)
# Get the ratings: this is the intersection of two raters, taken in processRatings.R and mergeRating.R
load('../Data/ratingIntersect.rda', verbose = T)
# Pull out the response column of the rows we will remove - c(113:120, 433:440, 1249:1256) from ratings
# These are the second attempts of 3 participants who did the task twice
responses_to_remove <- ratings[c(113:120, 433:440, 1249:1256), ]
# Check these responses match the responses and indices in duplicates
all(responses_to_remove$response %in% duplicates$response) # TRUE
# Remove rows c(113:120, 433:440, 1249:1256) from ratings
ratings <- ratings[-c(113:120, 433:440, 1249:1256), ] # 2040 of 10
# Merge df with ratings and remove the duplicate response column
rated_explans <- cbind(df, ratings)[, -12]
# Now we have a df of 2040 rows and 14 columns: mindsCode, tag, response, digit1:digit6, a:h, unc
# Save rated explanations
save(rated_explans, file = '../Data/ratedExplans.rda')
# Run source scripts
source(knitr::purl('01preprocess.Rmd'))
setwd("~/Documents/GitHub/gw/Exp1Prediction/Experiment/Scripts")
# Run source scripts
source(knitr::purl('01preprocess.Rmd'))
formatR::tidy_pipe()
View(pizpar)
rm(list = ls())
####################################################
#### Preprocess gwExp1 behavioural data  ###########
####################################################
library(stringi)
library(tidyverse)
rm(list = ls())
# Read in data downloaded as long from Testable
data <- read.csv("../Data/dataJan23.csv") # 1456 obs of 41 vars
# Choose only active rows that have a participant code
data <-  data |>
filter(mindsCode!="") # 1440 obs of 41 vars = 90 ppts
# Reverse response columns for group 2
data <- data |>
mutate(flipped = if_else(subjectGroup=='2', stri_reverse(responseCode), responseCode))
# Copy just in case
data$flipped2 <- data$flipped
# Split out the response column and remove delimiter |
# These names are needed due to the different starting points of the agents, different food was visible
data <- separate(data = data, col = flipped2, into = c("short_inv", "long_inv", "short_vis", "long_vis"), sep = "\\|")
# The convention of eg. 'short path to visible food' was used for this part of the project
data$short_vis <- as.numeric(data$short_vis)
data$long_vis <- as.numeric(data$long_vis)
data$short_inv <- as.numeric(data$short_inv)
data$long_inv <- as.numeric(data$long_inv)
# New smaller df with columns we need
df <- data |>
select(mindsCode, subjectGroup, stim1, rowNo, note1, short_vis, long_vis, short_inv, long_inv)
# Although the minimum allowable answer was 1, there are a few undetected 0s. Best to remove these trials
df[df == 0] <- NA
df <- na.omit(df) # 1421 rows - we lost 19
# The next sections are rather clumsy because I wrote them when I was learning... Keep for now and maybe tidy later
# Set columns for what the condition tags actually mean
df <- df |>
mutate(Preference = if_else(grepl("F", note1), 'Hot dogs', 'Absent'))
df <- df |>
mutate(Knowledge = if_else(grepl("K", note1), 'Knows area', 'Does not know area'))
df <- df |>
mutate(Character = if_else(grepl("L", note1), 'Lazy', 'Sporty'))
df <- df |>
mutate(Start = if_else(grepl("A", stim1), 'Hot dogs visible', 'Pizza visible'))
# Set as factors for the regressions
df$Preference <- factor(df$Preference, levels = c('Absent', 'Hot dogs'),labels = c('Absent', 'Hot dogs'))
df$Knowledge <- factor(df$Knowledge, levels = c('Does not know area', 'Knows area'), labels = c('No', 'Yes'))
df$Character <- factor(df$Character, levels = c('Lazy', 'Sporty'), labels = c('Lazy', 'Sporty'))
df$Start <- factor(df$Start, levels = c('Pizza visible', 'Hot dogs visible'), labels = c('Pizza visible', 'Hot dogs visible'))
# Recode things and make the order of everything as consistent as possible
df <- df |>
mutate( lik_short_pizza = if_else(Start=="Hot dogs visible",
short_inv, short_vis),
lik_long_pizza = if_else(Start=="Hot dogs visible",
long_inv, long_vis),
lik_short_hotdog = if_else(Start=="Hot dogs visible",
short_vis, short_inv),
lik_long_hotdog = if_else(Start=="Hot dogs visible",
long_vis, long_inv)) |>
select(-short_vis, -long_vis, -short_inv, -long_inv)
df <- df |> mutate(lik_sum = lik_short_pizza + lik_long_pizza + lik_short_hotdog + lik_long_hotdog,
p_short_pizza = lik_short_pizza/lik_sum,
p_long_pizza = lik_long_pizza/lik_sum,
p_short_hotdog = lik_short_hotdog/lik_sum,
p_long_hotdog = lik_long_hotdog/lik_sum,
p_long = p_long_pizza + p_long_hotdog,
p_hotdog = p_short_hotdog + p_long_hotdog)
df <- df |>
mutate(Preference = factor(Preference, levels = c('Absent','Hot dogs'), labels = c('Absent','Hotdog')),
Knowledge = factor(Knowledge, levels = c('No','Yes')),
Character = factor(Character, levels = c('Lazy','Sporty')),
Start = factor(Start, levels = c('Pizza visible','Hot dogs visible'), labels = c('See_pizza','See_hotdog')),
P = factor(Preference, levels = c('Absent','Hotdog'), labels = 0:1),
K = factor(Knowledge, levels = c('No','Yes'), labels = 0:1),
C = factor(Character, levels = c('Lazy','Sporty'), labels = 0:1),
S = factor(Start, levels = c('See_pizza','See_hotdog'), labels = 0:1),
SituationVerbose = paste0(Preference, Knowledge,Character, Start),
Situation = paste0(P,K,C,S),
mindsCode = factor(mindsCode, levels = unique(mindsCode)),
id = factor(mindsCode, levels = unique(mindsCode), labels = 1:length(unique(mindsCode)))) |> arrange(id, S,C,K,P)
df <- df |>
mutate(SituationVerbose = factor(SituationVerbose, levels = SituationVerbose[1:16]),
Situation = factor(Situation, levels = Situation[1:16]))
# Save the df as an .Rda
save(df, file = '../Data/gwExp1data.Rda')
rm(list = ls())
source(knitr::purl('find_modelSD.Rmd')) # to find best fitting causal model from cleaned Exp1 behavioural data
setwd("~/Documents/GitHub/gw/Exp1Prediction/Model/Scripts")
source(knitr::purl('find_modelSD.Rmd')) # to find best fitting causal model from cleaned Exp1 behavioural data
source(knitr::purl('find_modelSD.Rmd')) # to find best fitting causal model from cleaned Exp1 behavioural data
View(df)
formatR::tidy_pipe()
## ---------------------------------------------------------------------------------------------------------------
rm(list=ls())
load('../../Experiment/Data/gwExp1data.Rda')
View(df)
View(df)
# Get the complete target distribution over all outcomes
td <- df |>
group_by(Situation) |>
summarise(p_short_pizza = mean(p_short_pizza, na.rm=T),
p_long_pizza = mean(p_long_pizza, na.rm=T),
p_short_hotdog = mean(p_short_hotdog, na.rm=T),
p_long_hotdog = mean(p_long_hotdog, na.rm=T)) |>
data.frame()
View(td)
td <- td[,2:5] # 16 obs of 4
# Calculate marginal probabilities for path and destination
td_path <- (df |>
group_by(Situation) |>
summarise(p_long = mean(p_long, na.rm=T)))$p_long
td_destination <- (df |>
group_by(Situation) |>
summarise(p_hotdog = mean(p_hotdog, na.rm=T)))$p_hotdog
state_names <- c("P", "K", "C", "S", "PK", "PC", "PS", "KC", "KS", "CS")
# 59049 obs of 10 vars (3^10)
structures <- expand.grid(P = -1:1,
K = -1:1,
C = -1:1,
S = -1:1,
PK = -1:1,
PC = -1:1,
PS = -1:1,
KC = -1:1,
KS = -1:1,
CS = -1:1)
init_full_par <- list(s = c(P = .5,
K = .5,
C = .5,
S = .5,
PK = .5,
PC = .5,
PS = .5,
KC = .5,
KS = .5,
CS = .5),
br = .5, # Base rate
tau = 1
)
# Create indexing grid for all possible situations - 16 obs of 4
ix <- expand.grid(S = 0:1,
C = 0:1,
K = 0:1,
P = 0:1)
# Keep it in same order as rest of code
ix <- ix[, c("P", "K", "C", "S")]
rownames(ix) <- NULL
get_mod_pred <- function(struct, par) {
# Use the predefined ix (created outside)
states <- ix
states$PK <- states$P * states$K
states$PC <- states$P * states$C
states$PS <- states$P * states$S
states$KC <- states$K * states$C
states$KS <- states$K * states$S
states$CS <- states$C * states$S
state_mat <- as.matrix(states[, state_names])
# Precompute indices
nor_idx <- which(struct == 1)
nandnot_idx <- which(struct == -1)
one_minus_s <- 1 - par$s
# Vectorized calculations
p <- sapply(1:nrow(state_mat), function(i) {
state <- state_mat[i, ]
nor <- c(1 - par$br, (one_minus_s[nor_idx] ^ state[nor_idx]))
nandnot <- (one_minus_s[nandnot_idx] ^ state[nandnot_idx])
(1 - prod(nor)) * prod(nandnot)
})
# Softmax
out <- data.frame(p0 = 1 - p, p1 = p)
out <- exp(as.matrix(out) / par$tau)
out <- out / rowSums(out)
out[, "p1"]
}
# Load fitted models from `01findModel.R`
load('../Data/fitted.rdata', verbose = 5)
###############################################################################################
############ Tidy best-fitting causal model and export for plotting #############
###############################################################################################
library(tidyverse)
rm(list=ls())
# Load fitted models from `01findModel.R`: 2 dfs of 59049 rows of 13 vars each, one for path and one for destination
load('../Data/fitted.rdata', verbose = 5)
# Count number of edges in each structure
fitted_path_mods$n_edge <- rowSums(structures!=0)
source(knitr::purl('graphing.Rmd'))
df <- read.csv('../Data/model.csv')
View(df)
formatR::tidy_pipe()
library(formatR)
tidy_source("graphing.R", indent = 2, pipe = TRUE, arrow = TRUE, wrap = TRUE, output = TRUE)
library(formatR)
tidy_source("graphing.R", indent = 2, pipe = TRUE, arrow = TRUE, wrap = TRUE, output = TRUE, file = 'graphs.R')
# All the possible variable names
labs <- c("P", "Pu", "K", "Ku", "C", "Cu", "S", "Su", "PK", "PKu", "PC", "PCu", "PS", "PSu", "KC", "KCu", "KS", "KSu",
"CS", "CSu", "Path")
# Set an empty square matrix of labsxlabs
fg <- matrix(0, 21, 21, dimnames = list(labs, labs))  # 21x21
# Set the path part to 1 for everything
for (i in 1:20) {
fg[i, 21] <- 1
}
# Manually set which vars of the adjacency matrix are 1. Surely there is a better way
fg[1, 9] <- fg[1, 11] <- fg[1, 13] <- 1  #P goes to PK, PC, PS etc
fg[3, 9] <- fg[3, 15] <- fg[3, 17] <- 1  #K
fg[5, 11] <- fg[5, 15] <- fg[5, 19] <- 1  #C
fg[7, 13] <- fg[7, 17] <- fg[7, 19] <- 1  #S
# New matrix of 21 rows and 2 columns and fill it with zeroes
locations <- matrix(0, 21, 2)
locations[, 2] <- c(rev(seq(0, 1, length.out = 20)), 0.5)  # sequence of 20 equally spaced numbers and reverses it, then adds 0.5. seems unrelated to the 'out' from before)
locations[, 1] <- c(rep(c(0, 0.15), 4), rep(c(0.4, 0.55), 6), 1)
pg <- dg <- fg
pg[rep(best_path == 0, each = 2), ] <- 0  # creates a logical vector of which elements of best_path are 0, then repeats it twice, then selects rows of the matrix corresponding to what is meant to be 0, then sets columns of these to zero.
# Just a manual best_path just now: will be replaced by the output from the model fitting
best_path <- c(0, 0, 1, 0, 0, 1, 0, 0, 0, 0)
pg[rep(best_path == 0, each = 2), ] <- 0  # creates a logical vector of which elements of best_path are 0, then repeats it twice,
View(pg)
keep <- pg[, 21] != 0 # Keep the ones not equal to 0
keep[21] <- T
pg <- pg[keep, keep]  # Keeps a 5x5 of only the elements of pg named as T in keep, then their values
View(pg)
# Once we have pg as the adjacency matrix, the single next line makes the graph, and everything after that is
# modifying it.  So the point becomes, is there an easier way to get the adjacency matrix from what we know?
g <- graph_from_adjacency_matrix(pg)
print(g)
## ---------------------------------------------------------------------------------------------------------------
## Suppose amat is your adjacency matrix (square, 0/1, row/col names = node names)
amat <- pg
edges <- which(amat == 1, arr.ind = TRUE)
edge_list <- data.frame(from = rownames(amat)[edges[, 1]], to = colnames(amat)[edges[, 2]])
## ---------------------------------------------------------------------------------------------------------------
## Create a list of formulas, e.g. PK ~ P means P -> PK
formulas <- lapply(split(edge_list, edge_list$to), function(x) {
as.formula(paste(x$to[1], "~", paste(x$from, collapse = " + ")))
})
# Combine into a dagify call
dag <- do.call(dagify, formulas)
# Now analyse or plot thsi with ggdag or dagitty
tidy_dag <- tidy_dagitty(dag)
ggdag(tidy_dag)  # Then add ggplot2 layers for more customisation
View(formulas)
#------- Customising the layout --------------
## Define coordinates for each node
coord_dag <- list(
x = c(P = 0, K = 1, C = 2, S = 3, Path = 2),
y = c(P = 2, K = 2, C = 1, S = 0, Path = 1))
# Create DAG with manual coordinates
my_dag <- dagify(
K ~ P,
C ~ K,
S ~ C,
Path ~ C + S,
coords = coord_dag)
# Plot with ggdag
ggdag(my_dag) + ggplot2::theme_minimal()
# ------- Customise layout of our actual path dag -----------------
coordinates(dag) <- list(
x = c(C = -1, Cu = -1.8, PC = 0, PCu = 0.5, Path = -0.5),
y = c(C = 2, Cu = 1.5, PC = 1.25,
PCu = 0.5, Path = -1))
ggdag(dag)
# Making it tidy has no later apparent effect on the spacing, but looks like we need it for setting the colours
tidy_dag <- tidy_dagitty(dag)
ggdag(tidy_dag) + remove_axes()
View(pg)
View(locations)
View(pg)
get_formulas <- function(pathvector, state_names) {
vars <- state_names[pathvector == 1]  # Get the names of the vars that are 1 in best_path
# if length(vars) > 1, add an edge between the elements of vars, from earlier to later
if (length(vars) > 1) {
for (i in 1:(length(vars) - 1)) {
from_var <- vars[i]
to_var <- vars[i + 1]
pg[which(rownames(pg) == from_var), which(colnames(pg) == to_var)] <- 1
}
}
vars_u <- paste0(vars, "u")  # Add 'u' to each of these names
all_vars <- c(vars, vars_u)  # Combine the two sets of names
formulas <- paste(all_vars, collapse = " + ")  # Create a string with all names separated by ' + '
formula <- paste("Path ~", formulas)  # Create the final formula string
return(formula)
}
# Test the function get_formulas
formula <- get_formulas(best_path, state_names)
state_names <- c("P", "K", "C", "S", "PK", "PC", "PS", "KC", "KS", "CS")
get_formulas <- function(pathvector, state_names) {
vars <- state_names[pathvector == 1]  # Get the names of the vars that are 1 in best_path
# if length(vars) > 1, add an edge between the elements of vars, from earlier to later
if (length(vars) > 1) {
for (i in 1:(length(vars) - 1)) {
from_var <- vars[i]
to_var <- vars[i + 1]
pg[which(rownames(pg) == from_var), which(colnames(pg) == to_var)] <- 1
}
}
vars_u <- paste0(vars, "u")  # Add 'u' to each of these names
all_vars <- c(vars, vars_u)  # Combine the two sets of names
formulas <- paste(all_vars, collapse = " + ")  # Create a string with all names separated by ' + '
formula <- paste("Path ~", formulas)  # Create the final formula string
return(formula)
}
# Test the function get_formulas
formula <- get_formulas(best_path, state_names)
print(formula)  # Should print something like "Path ~ K + Cu"
get_formulas <- function(pathvector, state_names) {
get_formulas <- function(pathvector, state_names) {
vars <- state_names[pathvector == 1]  # Get the names of the vars that are 1 in best_path
# if length(vars) > 1, add a formula between those elements of vars
if (length(vars) > 1) {
for (i in 1:(length(vars) - 1)) {
from_var <- vars[i]
to_var <- vars[i + 1]
# set a formula to add to the formulas list of to_var being predicted by from_var
formula <- paste(to_var, "~", from_var)
# Add this formula to the list of formulas
if (i == 1) {
formulas <- list(formula)
} else {
formulas <- c(formulas, list(formula))
}
}
vars_u <- paste0(vars, "u")  # Add 'u' to each of these names
all_vars <- c(vars, vars_u)  # Combine the two sets of names
formulas <- paste(all_vars, collapse = " + ")  # Create a string with all names separated by ' + '
formula1 <- paste("Path ~", formulas)  # Create the first, path formula string
# ormula2 will be the edges between those parts of vars which are 1
# In fact formula is a list or other allowing more than one formula
return(formula)
}
}
get_formulas <- function(pathvector, state_names) {
vars <- state_names[pathvector == 1]  # Get the names of the vars that are 1 in best_path
# if length(vars) > 1, add a formula between those elements of vars
if (length(vars) > 1) {
for (i in 1:(length(vars) - 1)) {
from_var <- vars[i]
to_var <- vars[i + 1]
# set a formula to add to the formulas list of to_var being predicted by from_var
formula <- paste(to_var, "~", from_var)
# Add this formula to the list of formulas
if (i == 1) {
formulas <- list(formula)
} else {
formulas <- c(formulas, list(formula))
}
}
vars_u <- paste0(vars, "u")  # Add 'u' to each of these names
all_vars <- c(vars, vars_u)  # Combine the two sets of names
formulas <- paste(all_vars, collapse = " + ")  # Create a string with all names separated by ' + '
formula1 <- paste("Path ~", formulas)  # Create the first, path formula string
# ormula2 will be the edges between those parts of vars which are 1
# In fact formula is a list or other allowing more than one formula
return(formula)
}
}
# Test the function get_formulas
formula <- get_formulas(best_path, state_names)
print(formula)  # Should print something like "Path ~ K + Cu"
get_formulas <- function(pathvector, state_names) {
vars <- state_names[pathvector == 1]  # Get the names of the vars that are 1 in best_path
# if length(vars) > 1, add a formula between those elements of vars
if (length(vars) > 1) {
for (i in 1:(length(vars) - 1)) {
from_var <- vars[i]
to_var <- vars[i + 1]
# set a formula to add to the formulas list of to_var being predicted by from_var
formula <- paste(to_var, "~", from_var)
# Add this formula to the list of formulas
if (i == 1) {
formulas <- list(formula)
} else {
formulas <- c(formulas, list(formula))
}
}
vars_u <- paste0(vars, "u")  # Add 'u' to each of these names
all_vars <- c(vars, vars_u)  # Combine the two sets of names
formulas <- paste(all_vars, collapse = " + ")  # Create a string with all names separated by ' + '
formula1 <- paste("Path ~", formulas)  # Create the first, path formula string
formulas <- c(formula1, formulas)  # Combine into a list of formulas
# In fact formula is a list or other allowing more than one formula
return(formulas)
}
}
# Test the function get_formulas
formula <- get_formulas(best_path, state_names)
print(formula)  # Should print something like "Path ~ K + Cu"
get_formulas <- function(pathvector, state_names) {
vars <- state_names[pathvector == 1]  # Get the names of the vars that are 1 in best_path
# set up an empty list of formulas
formulas <- list()
# if length(vars) > 1, add a formula between those elements of vars
if (length(vars) > 1) {
for (i in 1:(length(vars) - 1)) {
from_var <- vars[i]
to_var <- vars[i + 1]
# set a formula to add to the formulas list of to_var being predicted by from_var
formula <- paste(to_var, "~", from_var)
# Add this formula to the list of formulas
if (i == 1) {
formulas <- list(formula)
} else {
formulas <- c(formulas, list(formula))
}
}
vars_u <- paste0(vars, "u")  # Add 'u' to each of these names
all_vars <- c(vars, vars_u)  # Combine the two sets of names
varsforform <- paste(all_vars, collapse = " + ")  # Create a string with all names separated by ' + '
formula1 <- paste("Path ~", varsforform)  # Create the first, path formula string
formulas <- c(formula1, formulas)  # Combine into a list of formulas
}
return(formulas)
}
# Test the function get_formulas
formula <- get_formulas(best_path, state_names)
print(formula)  # Should print something like "Path ~ K + Cu"
# Combine into a dagify call
dag <- do.call(dagify, formula)
formula_list <- lapply(formula, as.formula)
dag <- do.call(dagify, formula_list)
tidy_dag <- tidy_dagitty(dag)
ggdag(tidy_dag)  # Then add ggplot2 layers for more customisation
# ------- Customise layout of our actual path dag -----------------
coordinates(dag) <- list(
x = c(C = -1, Cu = -1.8, PC = 0, PCu = 0.5, Path = -0.5),
y = c(C = 2, Cu = 1.5, PC = 1.25,
PCu = 0.5, Path = -1))
ggdag(dag)
# Done for path but not yet for destination (can prob use same function). Btw I deleted all the old script. Look on gwnotes for graphing or .rmd if you still need it
source(knit::purl('descriptives.rmd'))
# Done for path but not yet for destination (can prob use same function). Btw I deleted all the old script. Look on gwnotes for graphing or .rmd if you still need it
source(knitr::purl('descriptives.rmd'))
formatR::tidy_pipe()
# Load df 1421 of 27. Each row is one participant's response to one of the 16 situations. Was 1440 but 19 had 0s so were removed.
load('../../Experiment/Data/gwExp1data.Rda')
forscatter_long <- df |>
select(mindsCode, lik_short_pizza:lik_long_hotdog, Situation) |>
pivot_longer(
cols = lik_short_pizza:lik_long_hotdog,
names_to = "Choice",
values_to = "Rating"
)
View(forscatter_long)
View(df)
ggplot(forscatter_long, aes(x = Choice, y = Rating, color = Choice)) +
geom_beeswarm(cex = 0.3) +
facet_wrap(~Situation) +
labs(x = "Item", y = "Rating") +
theme_minimal() +
scale_x_discrete(guide = guide_axis(angle = 45))
counts <- df |>
select(mindsCode, lik_short_pizza:lik_long_hotdog, Situation) |>
pivot_longer(
cols = lik_short_pizza:lik_long_hotdog,
names_to = "item",
values_to = "rating"
) |>
group_by(Situation, item, rating) |>
summarise(count = n(), .groups = "drop")
View(counts)
View(counts)
ggplot(counts, aes(x = item, y = count, fill = as.factor(rating))) +
geom_bar(stat = "identity", position = "stack") +
facet_wrap(~Situation) +
labs(x = "Item", y = "Count", fill = "Rating") +
theme_minimal()
ggplot(forscatter_long, aes(x = Choice, y = Rating)) +
geom_point() +
geom_violin() +
#geom_jitter(width = 0.2, height = 0, size = 1.5, alpha = 0.7) +
facet_wrap(~Situation) +
theme_bw() +
labs(title = "Jittered Scatterplot Faceted by Situation",
x = "X Axis Label",
y = "Y Axis Label")
library(ggplot2)
# A violin plot with overlaid points, faceted by situation, still not brilliant
ggplot(forscatter_long, aes(x = Choice, y = Rating)) +
geom_point() +
geom_violin() +
#geom_jitter(width = 0.2, height = 0, size = 1.5, alpha = 0.7) +
facet_wrap(~Situation) +
theme_bw() +
labs(title = "Jittered Scatterplot Faceted by Situation",
x = "X Axis Label",
y = "Y Axis Label")
