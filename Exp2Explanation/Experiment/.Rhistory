plogp <- function(p) {
# bits, not nats
if(p==0) 0 else p*log2(p) # Consider why we can't just use p*log2(p). Because log 0 = inf
}
cat_entropy <- function(catv) {
-sum(sapply(catv,plogp))
}
require(combinat) # From googling "all list permutations in R"
probs <- c(0,.2,.3,.75)
hyps <- permn(probs) # Generates all permutations, where order doesn't matter it is 4x3x2x1
prior <- rep(1/24, nrow(hyps)) # Replace this with a prior over all hypotheses
cat_entropy(prior)
prior <- rep(1/24, nrow(hyps)) # Replace this with a prior over all hypotheses
View(hyps)
prior <- rep(1/24) # Replace this with a prior over all hypotheses
cat_entropy(prior)
View(cat_entropy)
knitr::opts_chunk$set(echo = TRUE)
require(DirichletReg) # We'll be using Dirichlet distributions. gtools includes rdirichlet and ddirichlet but not with log densities.
plogp <- function(p) {
# bits, not nats
if(p==0) 0 else p*log2(p) # Consider why we can't just use p*log2(p). Because log 0 = inf
}
cat_entropy <- function(catv) {
-sum(sapply(catv,plogp))
}
require(combinat) # From googling "all list permutations in R"
probs <- c(0,.2,.3,.75)
hyps <- permn(probs) # Generates all permutations, where order doesn't matter it is 4x3x2x1
prior <- rep(1/24) # Entropy if we know nothing is 0.19
cat_entropy(prior)
update_probs <- function(prior,choice,outcome) {
# x, below, is a list of probabilities under a specific hypothesis
#Likelihood function is a zero for all hypotheses incompatible with the outcome
#and 1 otherwise
likelihood <- function(this_hyp,this_choice,this_outcome) {
if (this_outcome==this_choice){
likelihood[this_hyp] <- 1
} else {
likelihood <- 0
}
}
likes <- sapply(hyps,function(h) {likelihood(h,choice,outcome)})
unnp <- likes*prior
z <- sum(unnp)
unnp/z
}
post <- update_probs(prior,choice=1,outcome=0)
print(post)
update_probs <- function(prior,choice,outcome) {
# x, below, is a list of probabilities under a specific hypothesis
#Likelihood function is a zero for all hypotheses incompatible with the outcome
#and 1 otherwise
likelihood <- function(this_hyp,this_choice,this_outcome) {
prob_this_outcome <- (this_hyp[this_choice]*this_outcome) + (1-this_hyp[this_choice]*(1-this_outcome))
}
likes <- sapply(hyps,function(h) {likelihood(h,choice,outcome)})
unnp <- likes*prior
z <- sum(unnp)
unnp/z
}
post <- update_probs(prior,choice=1,outcome=0)
print(post)
cat_entropy(post)
log(24)
log2(24)
# First we want the probability of each outcome in each hyp
# Then we take the weighted sum over hypothesis probabilities
expected_outcome <- function(i,ph) {
sum(hyps[i])*ph
}
print(expected_outcome(2,post))
# First we want the probability of each outcome in each hyp
# Then we take the weighted sum over hypothesis probabilities
expected_outcome <- function(i,ph) {
sum(sapply(hyps, function(hyp) {hyp[i]})*ph) # the sapply results in a vector of 24. sapply loops over column and applies a function to each element
}
print(expected_outcome(2,post))
expected_entropy <- function(choice,p_hyps) {
pwin <- expected_outcome(choice,p_hyps)
cat_entropy(pwin)
}
print(expected_entropy(2,post))
#For steph 2
library(igraph)
library(tidyverse)
nodes<-c('Preference','Character','Closer','Knowledge','Visible','Choice')
graph<-matrix(c(0,0,0,0,0,1,
0,0,0,0,0,1,
0,0,0,0,0,1,
0,0,0,0,0,1,
0,0,0,0,0,1,
0,0,0,0,0,0), ncol = 6, byrow=T)
G<-graph.adjacency(graph)
View(G)
V(G)$label<-V(G)$name<-nodes
V(G)$size <- 50
V(G)$color <- 'white'
E(G)$color <- 'black'
E(G)$width <- 2
plot(G)
?igraph
V(G)$color <- 'blue'
E(G)$color <- 'black'
E(G)$width <- 2
plot(G)
V(G)$color <- 'white'
E(G)$color <- 'red'
E(G)$width <- 2
plot(G)
#I figured its easier to think about in the form of a data frame
#So we have a column indexing the state for each cause using a factor (0,1)
#And a column for the probabilities for each unique combination
pChoice<-data.frame(expand.grid(list(Preference=c(0,1),
Character=c(0,1),
Closer=c(0,1),
Knowledge=c(0,1),
Visible = c(0,1)))) %>%
mutate(Preference = factor(Preference, levels = c(0,1),
labels = c('Absent','Hotdog')),
Character = factor(Character, levels = c(0,1),
labels = c('Lazy','Sporty')),
Closer = factor(Closer, levels = c(0,1),
labels = c('Pizza','Hotdog')),
Knowledge = factor(Knowledge, levels = c(0,1),
labels = c('No','Yes')),
Visible = factor(Visible, levels = c(0,1),
labels = c('Pizza','Hotdog')),
p_choose_hotdog = NA)
View(pChoice)
head(pChoice)
#Default preference for hotdog
baserate<-.5
#Strength of preference, strength of character
strengths<-list(preference=.5, character=.5)
#preference and character match only promote hotdog choice so long as the person either
#(a) knows the area or (b) can see the hotdog
tmp1<- pChoice$Knowledge=='Yes' | pChoice$Visible=='Hotdog'
#character match only promotes pizza choice so long as the person
#(a) knows the area or (b) can see the hotdog
tmp2<-pChoice$Knowledge=='Yes' | pChoice$Visible=='Pizza'
pChoice$p_choose_hotdog<-(1-(1-baserate) *
(1-strengths[['preference']]*as.numeric(pChoice$Preference=='Hotdog')*tmp1) *
#preference for hotdog pushes toward hotdog
(1-strengths[['character']]* as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Hotdog' |
#character match to distance to hotdog pushes toward hotdog
pChoice$Character=='Sporty' & pChoice$Closer=='Pizza')*tmp1)) *
#end of the noisy OR of generative causes
(1-strengths[['character']] * as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Pizza' |
#character match to distance to pizza pushes toward pizza
pChoice$Character=='Sporty' & pChoice$Closer=='Hotdog') * tmp2)
View(pChoice)
#Here's how it looks
pChoice
#Anc here's an example of using it to maker a basic counterfactual explanation type model
#Let's suppose a person chooses pizza in situation 15
case<-cbind(pChoice[15,], Choice='Pizza')
case
#Was it reasonably to be expected given the situation (in this case yes)
p_actual<-1-case$p_choose_hotdog
?unlist
#What features of the situation contributed most to its being selected?
#counterfactual contrasts:
p_counterfactual<-1-unlist(c(pChoice %>% filter(Preference!=case$Preference,
Character==case$Character,
Closer ==case$Closer,
Knowledge==case$Knowledge,
Visible==case$Visible) %>% select(preference=p_choose_hotdog),
pChoice %>% filter(Preference==case$Preference,
Character!=case$Character,
Closer ==case$Closer,
Knowledge==case$Knowledge,
Visible==case$Visible) %>% select(character=p_choose_hotdog),
pChoice %>% filter(Preference==case$Preference,
Character==case$Character,
Closer !=case$Closer,
Knowledge==case$Knowledge,
Visible==case$Visible) %>% select(closer=p_choose_hotdog),
pChoice %>% filter(Preference==case$Preference,
Character==case$Character,
Closer ==case$Closer,
Knowledge!=case$Knowledge,
Visible==case$Visible) %>% select(knowledge=p_choose_hotdog),
pChoice %>% filter(Preference==case$Preference,
Character==case$Character,
Closer ==case$Closer,
Knowledge==case$Knowledge,
Visible!=case$Visible) %>% select(visible=p_choose_hotdog)))
View(case)
dependence<-p_actual-p_counterfactual
#In this case we might reasonably blame her lazy character or the fact that the pizza was closer
Collapse
View(case)
View(pChoice)
dependence
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_push * char_push
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
pref_match_hotdog <- as.numeric(pChoice$Preference=='Hotdog')
char_match_hotdog <- as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Hotdog' |
pChoice$Character=='Sporty' & pChoice$Closer=='Pizza')
char_match_pizza <- as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Pizza' |
#character match to distance to pizza pushes toward pizza
pChoice$Character=='Sporty' & pChoice$Closer=='Hotdog')
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
#preference and character match only promote hotdog choice so long as the person either
#(a) knows the area or (b) can see the hotdog ie generative ie things that make you want hotdog
prom_hotdog <- pChoice$Knowledge=='Yes' | pChoice$Visible=='Hotdog'
#character match only promotes pizza choice so long as the person
#(a) knows the area or (b) can see the hotdog ie preventative factor ie things that amke you want pizza
prom_pizza <- pChoice$Knowledge=='Yes' | pChoice$Visible=='Pizza'
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_push * char_push
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(strengths[['character']], strengths[['preference']], baserate))
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate))
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate))
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate)))
# My meddling
hotdog_promotion <- function() {
pref_prom_hotdog <- 1 - strengths[['preference']] * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - strengths[['character']] * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion())
# My meddling
hotdog_promotion <- function() {
pref_prom_hotdog <- 1 - strengths[['preference']] * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - strengths[['character']] * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1- strengths[['character']] *char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion())
22/110
2.002/10.10
5.005/10.01
2.005/10.1
2.002/10.1
52/110
exp(100)
exp(1)
runif(4)
sessionInfo()
sessionInfo()
sessionInfo()
install.packages("afex")
install.packages("faux")
library(broom, tidyverse, faux, afex)
library(broom)
library(faux)
library(afex)
R.version()
R.Version()
.libPaths()
.libPaths()
R.Version()
# ------- Prelims -----------
library(tidyverse)
library(ggplot2)
# ----------- Define an example prior df -------------------------
# Here define two causal vars and an exogenous noise variable for each (i.e. var epsilon A goes with A)
# in the exp setting this is 0.5
p_A <- c(.1,.9) # ie A usually has value 1... base rate for cause
p_epsA <- c(.7,.3) #... most of the time the noise var for a doesn't occur. for a to work it needs a and exp a. a is usually present but ogten doesnt work cos of noise term not working
p_B <- c(.8,.2) # B rarely fires 1...
p_epsB <- c(.3,.7) # but when it does it is strong
# And wrap them into a df called prior. Later the function should take dfs of this format:
# i.e. any number of causes as the rows, and the probs of them taking 0 and 1 as cols
params <- data.frame(rbind(p_A, p_epsA, p_B, p_epsB))
colnames(params) <- c(0,1)
# Other values set outside for now
N_cf <- 1000L # How many counterfactual samples to draw
s <- .7 # Stability
n_causes <- nrow(params)
causes <- rownames(params)
# Make a df of all combinations of variable settings
df <- expand.grid(rep(list(c(0,1)),n_causes), KEEP.OUT.ATTRS = F)
# ... with variables as the column names
colnames(df) <- causes
worlds <- nrow(df)
View(df)
structure <- 'disjunctive'
if (structure=="disjunctive") {
df$E <- as.numeric((df[1] & df[2]) | (df[3] & df[4]))
}
# Can replace with this - if rename - it is deterministic - literally gives specific outcome for set 3 causes, needs actual input. mechanical tell syou whether effects occurred given setting
# df$effect <- max( c(min(c1,e1), min(c2,e2), min(c3, e3), min(c2*c3, e23))) # BUT SAME PROBLEM - HOW TO AUTOMATICALLY DEAL WITH ANY NUMBER OF CAUSES?
mat <- as.matrix(df[,1:4])
View(mat)
# df2 <- as.matrix(df, dimnames=NULL)
# dimnames = list(c(1:16), c(causes))
# Replace every cell with the relevant indexed edge strength from params
for (k in 1:worlds){
for (cause in causes) {
a <- params[cause,df[k,cause]+1] # It needs the '+1' because r indexes from 1 not 0
mat[k,cause] <- a # ((then sometimes #*df[k,cause] if do at same time as structure but change later if need))
}
}
View(mat)
View(params)
# For each row of df, the prior is now the product of the same row of df2
df$Pr <- apply(mat, 1, prod) # parameter of the model
sum(df$Pr)
# Then loop to calculate cfs and assign causal responsibility
# Loop through possible world settings
for (c_ix in 1:worlds)
sd(3000)
?rbinom
N <- 10^4
rbinom(N,1,.3)
sd_v <- sd(v)
v <- rbinom(N,1,.3)
sd_v <- sd(v)
?sd
th <- 0.3*0.7
p <- 0.3
derived <- (N*p(1-p))^0.5
derived <- (N*p*(1-p))^0.5
derived <- (N*3000*(1-p))^0.5
(p*(1-p)/n)^0.5
(p*(1-p)/N)^0.5
((p*(1-p))/N)^0.5
sum(v)
((3050*(6950))/N)^0.5
(N*p*(1-p))^0.5
q <- 0.7
p*q
0.3*0.7
N*p*q
2100^0.5
sqrt(2100)
(p*q/N)^0.5
((p*q)/N)^0.5
0.198^0.5
pest <- mean(v)
var <- (pest*(1-pest))/N
sqrt(var)
n <- 100
p*q/n
sqrt(p*q/n)
v2 <- rbinom(n,1,.3)
sd(v2)
sqrt(p*q)
sd(pest*(1-pest))
n2 <- 100000
v3 <- rbinom(n2,1,.3)
sd(v3)
sd(v2)
sd(v)
sum(v)
mean(v)
r <- mean(v)
g <- 1-r
sqrt(r*g)
?file.access
install.packages("gander")
usethis::edit_r_environ()
usethis::edit_r_profile()
library(ggplot2)
library(gander)
install.packages('ellmer')
library(ellmer)
library(ellmer)
library(gander)
data("stackoverflow", package = "modeldata")
stackoverflow
```r
stackoverflow %>%
summarise(across(where(is.numeric), list(mean = mean, sd = sd), na.rm = TRUE))
usethis::edit_r_profile()
usethis::edit_r_profile()
library(ggplot2)
library(ellmer)
library(gander)
data("stackoverflow", package = "modeldata")
sapply(stackoverflow, function(x) if(is.numeric(x)) mean(x, na.rm = TRUE) else NA)
?gander
formatR::tidy_pipe()
formatR::tidy_pipe()
install.packages('formatR')
formatR::tidy_pipe()
setwd("~/Documents/GitHub/Collider_cognition/Main_scripts_newexp")
formatR::tidy_pipe()
formatR::tidy_source('modelCombLesionstestnewpipe.R', pipe = TRUE)
formatR::tidy_source('modelCombLesionstestnewpipe.Rmd', pipe = TRUE)
knitr::opts_chunk$set(echo = FALSE, include = FALSE, tidy = TRUE)
#library(tidyverse)
#library(stringr)
# Script takes the processed data from the collider ppt expt (`DATA.RDATA`)
# (which was cleaned in `preprocessing.R`)
# and combines it with the pre-processed model predictions from `modpred_process2.R` (`tidied_preds4.csv`)
load('../Data/Data.Rdata', verbose = T) # This is one big df, 'data', 2580, of 215 ppts
data <- df2
mp <- read.csv('../model_data/tidied_predpn.csv') # 576 of 26 - 576 rows because: 3 pgroups x 12 trialtypes x 4 nodes x 4 prior possible settings of unobserved variables
#mp$cesm <- mp$cesm*2 # a test for why the QL version is different
mp$pgroup <- as.factor(mp$pgroup)
mp$node3 <- as.factor(mp$node3)
mp$trialtype <- as.factor(mp$trialtype)
mp$structure <- as.factor(mp$structure)
mp$E.x <- as.factor(mp$E.x)
mp$E.y <- as.factor(mp$E.y)
# Condition 1
mp <- mp %>% #
mutate(Actual = case_when(
node2 == 'A' ~ A==E.x,
node2 == 'B' ~ B==E.x,
node2 == 'Au' ~ Au==E.x,
node2 == 'Bu' ~ Bu==E.x
))
setwd("~/Documents/GitHub/gw/Later_rating25")
formatR::tidy_pipe()
# Get the ppt data - 2040 of 10
df <- read.csv('../Exp2Explanation/Experiment/processedData.csv')
# Get the ratings: this is the intersection of two raters, taken in processRatings.R and mergeRating.R
ratings <- read.csv('ratings.csv')
ratings <- ratings[,-1]
View(ratings)
formatR::tidy_pipe()
# Previously this project was called 'ug data rerun' so that name crops up sometimes
#library(tidyverse)
rm(list = ls())
# This is the data 1.5MB saved directly from testable. Also exists in wide format
data <- read.csv('rerundata.csv') # 2838 of 47
setwd("~/Documents/GitHub/gw/Exp2Explanation/Experiment")
# This is the data 1.5MB saved directly from testable. Also exists in wide format
data <- read.csv('rerundata.csv') # 2838 of 47
# Get just the responses lines - 2064 - and filter for relevant info which is just subjectID, condition tag, and the reponse
df <- data |>
filter(trialText!="") |>
select(mindsCode, tag, response)
# Get just the responses lines - 2064 - and filter for relevant info which is just subjectID, condition tag, and the reponse
df <- data |>
filter(trialText!="") |>
select(mindsCode, tag, response)
# Previously this project was called 'ug data rerun' so that name crops up sometimes
library(tidyverse)
# Get just the responses lines - 2064 - and filter for relevant info which is just subjectID, condition tag, and the reponse
df <- data |>
filter(trialText!="") |>
select(mindsCode, tag, response)
View(df)
# There is a mistake in the data where 3 participants completed it twice,
# giving good faith answers on two different occasions. Decided to remove second attempts
# Remove duplicates - 2040
duplicate_indices <- df |>
group_by(mindsCode) |>
mutate(row_index = row_number()) |>
filter(row_index > 8) |>
pull(which(df$mindsCode %in% unique(.$mindsCode) & !1:nrow(df) %in% which(df$mindsCode %in% unique(.$mindsCode) & df$mindsCode %in% (df |> group_by(mindsCode) |> filter(row_number() <= 8) |> pull(mindsCode)))))
View(data)
View(data)
# Get just the responses lines - 2064 - and filter for relevant info which is just subjectID, condition tag, and the reponse
df <- data |>
filter(trialText!="") |>
mutate(index <- 1:nrow()) |>
select(index, mindsCode, tag, response)
# Get just the responses lines - 2064 - and filter for relevant info which is just subjectID, condition tag, and the reponse
df <- data |>
filter(trialText!="") |>
select(mindsCode, tag, response)
df$index <- 1:nrow(df)
View(df)
# There is a mistake in the data where 3 participants completed it twice,
# giving good faith answers on two different occasions. Decided to remove second attempts
# Remove duplicates - 2040
duplicate_indices <- df |>
group_by(mindsCode) |>
filter(row_number() > 8) |>
pull(index)
?pull
keep_indices <- df |>
group_by(mindsCode) |>
filter(row_number() <= 8) |>
pull(index)
print(keep_indices)
duplicate_indices
duplicate_indices %in% keep_indices
c(113:120, 433:440)
